{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHnbGR5wpCL8"
   },
   "source": [
    "# CSE 291 Assignment 2 BiLSTM CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rs2O4920pCob"
   },
   "source": [
    "## Download Data/Eval Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hmfarI0hpHj6",
    "outputId": "1e2a9af7-b445-47aa-e38b-3b6add0723e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-25 10:12:16--  https://raw.githubusercontent.com/sighsmile/conlleval/master/conlleval.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7502 (7.3K) [text/plain]\n",
      "Saving to: ‘conlleval.py.1’\n",
      "\n",
      "\r",
      "conlleval.py.1        0%[                    ]       0  --.-KB/s               \r",
      "conlleval.py.1      100%[===================>]   7.33K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-05-25 10:12:17 (61.5 MB/s) - ‘conlleval.py.1’ saved [7502/7502]\n",
      "\n",
      "--2021-05-25 10:12:17--  https://raw.githubusercontent.com/tberg12/cse291spr21/main/assignment2/train.data.quad\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 745734 (728K) [text/plain]\n",
      "Saving to: ‘train.data.quad.1’\n",
      "\n",
      "train.data.quad.1   100%[===================>] 728.26K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2021-05-25 10:12:17 (22.0 MB/s) - ‘train.data.quad.1’ saved [745734/745734]\n",
      "\n",
      "--2021-05-25 10:12:17--  https://raw.githubusercontent.com/tberg12/cse291spr21/main/assignment2/dev.data.quad\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 179141 (175K) [text/plain]\n",
      "Saving to: ‘dev.data.quad.1’\n",
      "\n",
      "dev.data.quad.1     100%[===================>] 174.94K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2021-05-25 10:12:17 (14.7 MB/s) - ‘dev.data.quad.1’ saved [179141/179141]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/sighsmile/conlleval/master/conlleval.py\n",
    "!wget https://raw.githubusercontent.com/tberg12/cse291spr21/main/assignment2/train.data.quad\n",
    "!wget https://raw.githubusercontent.com/tberg12/cse291spr21/main/assignment2/dev.data.quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0CMvXrmwpNCM",
    "outputId": "b548bb5b-a220-40f9-8b45-dc93e173f5d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import conlleval_own\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.vocab import Vocab\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import random\n",
    "\n",
    "SEED = 291\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "id": "5gL1Rss8FG87"
   },
   "outputs": [],
   "source": [
    "model_name = 'crf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOBmqHytpTGs"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKfmSZs8pPBV",
    "outputId": "7c032d1b-b692-4154-e912-afa51d79d945"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train word vocab: 3947 symbols.\n",
      "Train label vocab: 10 symbols: ['<start>', '<stop>', 'O', 'I-PER', 'I-ORG', 'I-LOC', 'I-MISC', 'B-MISC', 'B-ORG', 'B-LOC']\n",
      "Train data: 3420 sentences.\n",
      "Valid data: 800\n",
      "Pusan 0000 0000 0000 0000 0000 0000\n",
      "I-ORG O O O O O O\n",
      "Earlier this month , <unk> denied a Kabul government statement that the two sides had agreed to a ceasefire in the north .\n",
      "O O O O I-PER O O I-LOC O O O O O O O O O O O O O O O\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = 'train.data.quad'\n",
    "VALID_DATA = 'dev.data.quad'\n",
    "UNK = '<unk>'\n",
    "PAD = '<pad>'\n",
    "START_TAG = \"<start>\"  # you can add this explicitly or use it implicitly in your CRF layer\n",
    "STOP_TAG = \"<stop>\"    # you can add this explicitly or use it implicitly in your CRF layer\n",
    "\n",
    "\n",
    "def read_conll_sentence(path):\n",
    "    \"\"\" Read a CONLL-format sentence into vocab objects\n",
    "    Args:\n",
    "        :param path: path to CONLL-format data file\n",
    "        :param word_vocab: Vocabulary object for source\n",
    "        :param label_vocab: Vocabulary object for target\n",
    "    \"\"\"\n",
    "    sent = [[], []]\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            if line:\n",
    "                # replace numbers with 0000\n",
    "                word = line[0]\n",
    "                word = '0000' if word.isnumeric() else word\n",
    "                sent[0].append(word)\n",
    "                sent[1].append(line[3])\n",
    "            else:\n",
    "                yield sent[0], sent[1]\n",
    "                sent = [[], []]\n",
    "\n",
    "\n",
    "def prepare_dataset(dataset, word_vocab, label_vocab):\n",
    "    dataset = [\n",
    "      [\n",
    "        torch.tensor([word_vocab.stoi[word] for word in sent[0]], dtype=torch.long),\n",
    "        torch.tensor([label_vocab.stoi[label] for label in sent[1]], dtype=torch.long),\n",
    "      ]\n",
    "      for sent in dataset\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# load a list of sentences, where each word in the list is a tuple containing the word and the label\n",
    "train_data = list(read_conll_sentence(TRAIN_DATA))\n",
    "train_word_counter = Counter([word for sent in train_data for word in sent[0]])\n",
    "train_label_counter = Counter([label for sent in train_data for label in sent[1]])\n",
    "word_vocab = Vocab(train_word_counter, specials=(UNK, PAD), min_freq=2)\n",
    "if(model_name == 'crf'):\n",
    "  label_vocab = Vocab(train_label_counter, specials=(START_TAG, STOP_TAG), min_freq=1)\n",
    "else:\n",
    "  label_vocab = Vocab(train_label_counter, specials=(), min_freq=1)\n",
    "train_data = prepare_dataset(train_data, word_vocab, label_vocab)\n",
    "print('Train word vocab:', len(word_vocab), 'symbols.')\n",
    "print('Train label vocab:', len(label_vocab), f'symbols: {list(label_vocab.stoi.keys())}')\n",
    "valid_data = list(read_conll_sentence(VALID_DATA))\n",
    "valid_data = prepare_dataset(valid_data, word_vocab, label_vocab)\n",
    "print('Train data:', len(train_data), 'sentences.')\n",
    "print('Valid data:', len(valid_data))\n",
    "\n",
    "print(' '.join([word_vocab.itos[i.item()] for i in train_data[0][0]]))\n",
    "print(' '.join([label_vocab.itos[i.item()] for i in train_data[0][1]]))\n",
    "\n",
    "print(' '.join([word_vocab.itos[i.item()] for i in valid_data[1][0]]))\n",
    "print(' '.join([label_vocab.itos[i.item()] for i in valid_data[1][1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "id": "ZKuemIBqgfci"
   },
   "outputs": [],
   "source": [
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "## This function calculates the logsumexp for an entire matrix. It has been modified from the original version to\n",
    "## suit my requirements in the code\n",
    "def log_sum_exp(vec_mat):\n",
    "    max_vector = torch.max(vec_mat, dim = 1).values\n",
    "    log_exp_sum = torch.log(torch.sum(torch.exp(vec_mat - max_vector.view(-1, 1)), dim = 1))\n",
    "    log_exp_sum_final = max_vector + log_exp_sum\n",
    "    return log_exp_sum_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuL6lnJjgfci"
   },
   "source": [
    "## BISLTM Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "3XQjHae6gfci"
   },
   "outputs": [],
   "source": [
    "# Starter code implementing a BiLSTM Tagger\n",
    "# which makes locally normalized, independent\n",
    "# tag classifications at each time step\n",
    "\n",
    "class BiLSTMTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, tag_vocab_size, embedding_dim, hidden_dim, dropout=0.3):\n",
    "        super(BiLSTMTagger, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tagset_size = tag_vocab_size\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim).to(device)\n",
    "        self.bilstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True, batch_first=True).to(device)\n",
    "        self.tag_projection_layer = nn.Linear(hidden_dim, self.tagset_size).to(device)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
    "\n",
    "    def compute_lstm_emission_features(self, sentence):\n",
    "        hidden = self.init_hidden()\n",
    "        embeds = self.dropout(self.word_embeds(sentence))\n",
    "        bilstm_out, hidden = self.bilstm(embeds, hidden)\n",
    "        bilstm_out = self.dropout(bilstm_out)\n",
    "        bilstm_out = bilstm_out\n",
    "        bilstm_feats = self.tag_projection_layer(bilstm_out)\n",
    "        return bilstm_feats\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        bilstm_feats = self.compute_lstm_emission_features(sentence)\n",
    "        return bilstm_feats.max(-1)[0].sum(), bilstm_feats.argmax(-1)\n",
    "\n",
    "    def loss(self, sentence, tags):\n",
    "        bilstm_feats = self.compute_lstm_emission_features(sentence)\n",
    "        # transform predictions to (n_examples, n_classes) and ground truth to (n_examples)\n",
    "        return torch.nn.functional.cross_entropy(\n",
    "              bilstm_feats.view(-1, self.tagset_size), \n",
    "              tags.view(-1), \n",
    "              reduction='sum'\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNNmZx_Uqy7q"
   },
   "source": [
    "## BiLSTM CRF Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "id": "ex47Fuj0gfcj"
   },
   "outputs": [],
   "source": [
    "## Class BI-SLTMS CRF tagger\n",
    "\n",
    "## This code has been referenced and inspired from https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html\n",
    "## Although, I have written the entire code myself and vectorized it on my own to speed up the processing.\n",
    "## Logic at some places in the code might also be referenced from Taylor's lecture 7 on crf\n",
    "class BiLSTMCRFTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, tag_vocab_size, embedding_dim, hidden_dim, dropout=0.3):\n",
    "        super(BiLSTMCRFTagger, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tagset_size = tag_vocab_size\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim).to(device)\n",
    "        self.bilstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True, batch_first=True).to(device)\n",
    "        self.tag_projection_layer = nn.Linear(hidden_dim, self.tagset_size).to(device)\n",
    "        self.transition_vals = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size))\n",
    "        self.transition_vals.data[label_vocab.stoi[START_TAG], :] = -10000.\n",
    "        self.transition_vals.data[:, label_vocab.stoi[STOP_TAG]] = -10000.\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
    "\n",
    "    def compute_lstm_emission_features(self, sentence):\n",
    "        hidden = self.init_hidden() ## hideen state of the bilstm (hidden, cell) num_dir*num_layers x batchsize x hidden size\n",
    "        embeds = self.dropout(self.word_embeds(sentence))\n",
    "        bilstm_out, hidden = self.bilstm(embeds, hidden)\n",
    "        bilstm_out = self.dropout(bilstm_out)\n",
    "        bilstm_out = bilstm_out\n",
    "        bilstm_feats = self.tag_projection_layer(bilstm_out)\n",
    "        return bilstm_feats\n",
    "    \n",
    "    \n",
    "    def forward_algorithm_vectorized(self, bilstm_feats):\n",
    "        init_vals = torch.full((1, self.tagset_size), -10000.).to(device)\n",
    "        init_vals[0][label_vocab.stoi[START_TAG]] = 0.\n",
    "        prev_tag_vars = init_vals\n",
    "        for vec in bilstm_feats[0]:\n",
    "            emit_score = vec.view(-1, 1)\n",
    "            total_score = emit_score + self.transition_vals + prev_tag_vars\n",
    "            #print(prev_tag_vars, \"prev tag\")\n",
    "            prev_tag_vars = log_sum_exp(total_score).view(1, -1)\n",
    "            #print(prev_tag_vars, \"prev tag\")\n",
    "        final_val = prev_tag_vars + self.transition_vals[label_vocab.stoi[STOP_TAG]]\n",
    "        #print(final_val.shape, prev_tag_vars[0].shape,self.transition_vals[label_vocab.stoi[STOP_TAG]].shape)\n",
    "        total_score = log_sum_exp(final_val)\n",
    "        return total_score\n",
    "    \n",
    "    def find_numerator_score(self, bilstm_feats, tags):\n",
    "        score = torch.zeros(1).to(device)\n",
    "        tags = tags.view(tags.shape[1])\n",
    "        \n",
    "        tags = torch.cat([torch.tensor([label_vocab.stoi[START_TAG]], dtype=torch.long).to(device), tags])\n",
    "        #print(tags.shape)\n",
    "        for i, feat in enumerate(bilstm_feats[0]):\n",
    "            score = score + self.transition_vals[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transition_vals[label_vocab.stoi[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "        \n",
    "\n",
    "    def loss(self, sentence, tags):\n",
    "        bilstm_feats = self.compute_lstm_emission_features(sentence)\n",
    "        cumulative_score = self.forward_algorithm_vectorized(bilstm_feats)\n",
    "        numerator_score = self.find_numerator_score(bilstm_feats, tags)\n",
    "        loss = cumulative_score - numerator_score\n",
    "        #print(numerator_score, cumulative_score, loss)\n",
    "        return loss\n",
    " \n",
    "\n",
    "    def viterbi_decoding_vectorized(self, bilstm_feats):\n",
    "        \n",
    "        back_ptrs = []\n",
    "        init_vals = torch.full((1, self.tagset_size), -10000.).to(device)\n",
    "        init_vals[0][label_vocab.stoi[START_TAG]] = 0.\n",
    "        prev_tag_vars = init_vals\n",
    "        \n",
    "        for feat in bilstm_feats[0]:\n",
    "            total_score = self.transition_vals + prev_tag_vars\n",
    "            best_tag_vals, best_tag_inds = torch.max(total_score, dim = 1)\n",
    "            prev_tag_vars = best_tag_vals.view(1, -1) + feat.view(1, -1)\n",
    "            back_ptrs.append(best_tag_inds)\n",
    "        \n",
    "        final_score = prev_tag_vars + self.transition_vals[label_vocab.stoi[STOP_TAG]].view(1, -1)\n",
    "        best_tag_index = argmax(final_score)\n",
    "        best_tag_val = final_score[0,best_tag_index].view(1)\n",
    "        best_path = [best_tag_index]\n",
    "        curr_best = best_tag_index\n",
    "        for ptrs  in reversed(back_ptrs):\n",
    "            curr_best = ptrs[curr_best]\n",
    "            best_path.append(curr_best)\n",
    "            #print(\"Best path\", best_path)\n",
    "        #print(best_path, \"Best Path\")\n",
    "        \n",
    "        best_path.pop()\n",
    "        best_path.reverse()\n",
    "        return  best_tag_val, best_path\n",
    "            \n",
    "            \n",
    "    def forward(self, sentence):\n",
    "        bilstm_feats = self.compute_lstm_emission_features(sentence)\n",
    "        best_score, best_path  = self.viterbi_decoding_vectorized(bilstm_feats)\n",
    "        return best_score, best_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "id": "1I47mahWgfck"
   },
   "outputs": [],
   "source": [
    "## Dictionaries that store training loss, validation loss\n",
    "## The result.txt file stores the entire log during training to be refernced later for calcualting the metrics.\n",
    "training_loss_dict = []\n",
    "validation_loss_dict = []\n",
    "file_write = open(\"result.txt\", 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DH7JGSDAruUg"
   },
   "source": [
    "## Train / Eval loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "id": "Gw2He2cgrrF1"
   },
   "outputs": [],
   "source": [
    "def train(model, train_data, valid_data, word_vocab, label_vocab, model_name, epochs, log_interval=25):\n",
    "    losses_per_epoch = []\n",
    "    #evaluate(model, valid_data, word_vocab, label_vocab)\n",
    "    for epoch in range(epochs):\n",
    "        print(f'--- EPOCH {epoch} ---')\n",
    "        model.train()\n",
    "        losses_per_epoch.append([])\n",
    "        for i, (sent, tags) in enumerate(train_data):\n",
    "            model.zero_grad()\n",
    "            sent, tags = sent.to(device), tags.to(device)\n",
    "            sent = sent.unsqueeze(0)\n",
    "            tags = tags.unsqueeze(0)\n",
    "            loss = model.loss(sent, tags)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses_per_epoch[-1].append(loss.detach().cpu().item())\n",
    "            if i > 0 and i % log_interval == 0:\n",
    "                print(f'Avg loss over last {log_interval} updates: {np.mean(losses_per_epoch[-1][-log_interval:])}')\n",
    "\n",
    "        training_loss_dict.append(np.mean(losses_per_epoch[-1]))\n",
    "        evaluate(model, valid_data, word_vocab, label_vocab, model_name)\n",
    "        torch.save(model.state_dict(), 'models/ner_model_finak_{}_{}.pt'.format(model_name,epoch))\n",
    "\n",
    "\n",
    "def evaluate(model, dataset, word_vocab, label_vocab, model_name):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    scores = []\n",
    "    true_tags = []\n",
    "    pred_tags = []\n",
    "    sents = []\n",
    "    for i, (sent, tags) in enumerate(dataset):\n",
    "        with torch.no_grad():\n",
    "            sent, tags = sent.to(device), tags.to(device)\n",
    "            sent = sent.unsqueeze(0)\n",
    "            tags = tags.unsqueeze(0)\n",
    "            losses.append(model.loss(sent, tags).cpu().detach().item())\n",
    "            score, pred_tag_seq = model(sent)\n",
    "            scores.append(score.cpu().detach().numpy())\n",
    "            true_tags.append([label_vocab.itos[i] for i in tags.tolist()[0]])\n",
    "            if model_name == 'crf':\n",
    "              pred_tags.append([label_vocab.itos[i] for i in pred_tag_seq])\n",
    "            else:\n",
    "              pred_tags.append([label_vocab.itos[i] for i in pred_tag_seq[0]])\n",
    "            sents.append([word_vocab.itos[i] for i in sent[0]])\n",
    "\n",
    "    print('Avg evaluation loss:', np.mean(losses))\n",
    "    validation_loss_dict.append(np.mean(losses))\n",
    "    print(conlleval_own.evaluate([tag for tags in true_tags for tag in tags], [tag for tags in pred_tags for tag in tags], verbose=True))\n",
    "    print('\\n5 random evaluation samples:')\n",
    "    for i in np.random.randint(0, len(sents), size=5):\n",
    "        print('SENT:', ' '.join(sents[i]))\n",
    "        print('TRUE:', ' '.join(true_tags[i]))\n",
    "        print('PRED:', ' '.join(pred_tags[i]))\n",
    "    return sents, true_tags, pred_tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdJsc_y6rxdC"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mYP3hLDWgfcn",
    "outputId": "26ad76b3-64c8-4162-a48c-fe10e28f71da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- EPOCH 0 ---\n",
      "Avg loss over last 500 updates: 10.922907526373864\n",
      "Avg loss over last 500 updates: 8.740891910552978\n",
      "Avg loss over last 500 updates: 6.768220913887024\n",
      "Avg loss over last 500 updates: 5.950849521756172\n",
      "Avg loss over last 500 updates: 5.048518619418144\n",
      "Avg loss over last 500 updates: 5.1803735965490345\n",
      "Avg evaluation loss: 4.660816584825516\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 763 phrases; correct: 464.\n",
      "accuracy:  44.44%; (non-O)\n",
      "accuracy:  88.90%; precision:  60.81%; recall:  37.69%; FB1:  46.54\n",
      "              LOC: precision:  74.76%; recall:  43.25%; FB1:  54.80  210\n",
      "             MISC: precision:  44.44%; recall:  16.67%; FB1:  24.24  72\n",
      "              ORG: precision:  56.72%; recall:  37.13%; FB1:  44.88  201\n",
      "              PER: precision:  57.50%; recall:  43.63%; FB1:  49.61  280\n",
      "(60.81258191349934, 37.692932575142166, 46.5396188565697)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: Jim Brady then gave a big <unk> to the <unk> .\n",
      "TRUE: I-PER I-PER O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O\n",
      "SENT: <unk> 1996-08-26\n",
      "TRUE: I-LOC O\n",
      "PRED: O O\n",
      "SENT: The court <unk> <unk> 's <unk> that <unk> 's <unk> from Denmark , where he was arrested in March last year at the request of German authorities , was illegal .\n",
      "TRUE: O O O I-PER O O O I-PER O O O I-LOC O O O O O O O O O O O O O I-MISC O O O O O\n",
      "PRED: O O I-PER I-PER O O O O O O O O O O O O O O O O O O O O O I-MISC O O O O O\n",
      "SENT: \" My <unk> this year has been <unk> , \" <unk> said . \"\n",
      "TRUE: O O O O O O O O O O I-PER O O O\n",
      "PRED: O O O O O O O O O O I-PER O O O\n",
      "SENT: \" <unk> seen <unk> <unk> his goals ...\n",
      "TRUE: O O O I-PER O O O O\n",
      "PRED: O O O O O O O O\n",
      "--- EPOCH 1 ---\n",
      "Avg loss over last 500 updates: 4.318113517999649\n",
      "Avg loss over last 500 updates: 4.749459692001343\n",
      "Avg loss over last 500 updates: 3.753891598701477\n",
      "Avg loss over last 500 updates: 3.734674012899399\n",
      "Avg loss over last 500 updates: 3.0393529185056685\n",
      "Avg loss over last 500 updates: 3.224957614541054\n",
      "Avg evaluation loss: 3.467167318686843\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 846 phrases; correct: 627.\n",
      "accuracy:  56.94%; (non-O)\n",
      "accuracy:  91.74%; precision:  74.11%; recall:  50.93%; FB1:  60.38\n",
      "              LOC: precision:  84.96%; recall:  57.58%; FB1:  68.64  246\n",
      "             MISC: precision:  75.49%; recall:  40.10%; FB1:  52.38  102\n",
      "              ORG: precision:  61.47%; recall:  43.65%; FB1:  51.05  218\n",
      "              PER: precision:  73.93%; recall:  56.10%; FB1:  63.79  280\n",
      "(74.11347517730496, 50.93419983753046, 60.37554164660568)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: Dumbarton 0000 <unk> 0000\n",
      "TRUE: I-ORG O I-ORG O\n",
      "PRED: I-ORG O O O\n",
      "SENT: <unk> 1996-12-06\n",
      "TRUE: I-LOC O\n",
      "PRED: I-LOC O\n",
      "SENT: <unk> takes the <unk> on a trial basis , but new coach Glenn Hoddle said he saw no reason why the former Blackburn and <unk> <unk> should not make the post his own .\n",
      "TRUE: I-PER O O O O O O O O O O O I-PER I-PER O O O O O O O O I-ORG O I-ORG O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "SENT: <unk> that information about <unk> was \" as <unk> as the <unk> he <unk> \" , Jordan said he made some <unk> <unk> in the film .\n",
      "TRUE: O O O O I-PER O O O O O O O O O O O I-PER O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "SENT: <unk> - <unk> <unk> <unk> <unk> ( <unk> )\n",
      "TRUE: I-LOC O I-PER I-PER I-PER I-PER O O O\n",
      "PRED: O O I-PER I-PER I-PER I-PER O O O\n",
      "--- EPOCH 2 ---\n",
      "Avg loss over last 500 updates: 2.8906308146715163\n",
      "Avg loss over last 500 updates: 3.3039164440631867\n",
      "Avg loss over last 500 updates: 2.6594811568260193\n",
      "Avg loss over last 500 updates: 2.69075710105896\n",
      "Avg loss over last 500 updates: 2.2424870126247405\n",
      "Avg loss over last 500 updates: 2.522873221755028\n",
      "Avg evaluation loss: 2.9590956565737723\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 952 phrases; correct: 714.\n",
      "accuracy:  64.21%; (non-O)\n",
      "accuracy:  92.76%; precision:  75.00%; recall:  58.00%; FB1:  65.41\n",
      "              LOC: precision:  86.40%; recall:  64.74%; FB1:  74.02  272\n",
      "             MISC: precision:  76.74%; recall:  51.56%; FB1:  61.68  129\n",
      "              ORG: precision:  63.79%; recall:  50.49%; FB1:  56.36  243\n",
      "              PER: precision:  73.05%; recall:  60.98%; FB1:  66.47  308\n",
      "(75.0, 58.001624695369614, 65.41456710948235)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: Pakistan , who <unk> next week , are the third team in the <unk> World Series tournament .\n",
      "TRUE: I-LOC O O O O O O O O O O O O O I-MISC I-MISC O O\n",
      "PRED: I-LOC O O O O O O O O O O O O O I-MISC I-MISC O O\n",
      "SENT: <unk> <unk> <unk> on reports of a plan to build property <unk> <unk> $ 0000 billion in Jakarta and <unk> .\n",
      "TRUE: O I-ORG I-ORG O O O O O O O O O O O O O O I-LOC O I-LOC O\n",
      "PRED: O O O O O O O O O O O O O O O O O I-LOC O O O\n",
      "SENT: <unk> , 0000 , had complained of lower back <unk> since a trip to Taiwan in May , when <unk> forced her to go to <unk> <unk> <unk> for an <unk> .\n",
      "TRUE: I-PER O O O O O O O O O O O O O I-LOC O O O O O O O O O O I-LOC I-LOC I-LOC O O O O\n",
      "PRED: I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "SENT: In San Diego , Steve <unk> and <unk> <unk> <unk> in three runs <unk> as the San Diego <unk> built a <unk> lead after three innings and <unk> to an <unk> victory over the Philadelphia <unk> .\n",
      "TRUE: O I-LOC I-LOC O I-PER I-PER O I-PER I-PER O O O O O O O I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O I-ORG I-ORG O\n",
      "PRED: O I-LOC I-LOC O I-PER I-PER O I-PER I-PER I-PER O O O O O O I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O I-ORG I-ORG O\n",
      "SENT: <unk> AT SAN FRANCISCO\n",
      "TRUE: I-ORG O I-LOC I-LOC\n",
      "PRED: I-ORG O I-LOC O\n",
      "--- EPOCH 3 ---\n",
      "Avg loss over last 500 updates: 2.1961274762153624\n",
      "Avg loss over last 500 updates: 2.5105990816354753\n",
      "Avg loss over last 500 updates: 2.1038142874240875\n",
      "Avg loss over last 500 updates: 2.1791781108379364\n",
      "Avg loss over last 500 updates: 1.8216410388946533\n",
      "Avg loss over last 500 updates: 1.9798063781261444\n",
      "Avg evaluation loss: 2.7827335653454064\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1000 phrases; correct: 758.\n",
      "accuracy:  67.40%; (non-O)\n",
      "accuracy:  93.08%; precision:  75.80%; recall:  61.58%; FB1:  67.95\n",
      "              LOC: precision:  88.28%; recall:  70.52%; FB1:  78.41  290\n",
      "             MISC: precision:  77.17%; recall:  51.04%; FB1:  61.44  127\n",
      "              ORG: precision:  65.60%; recall:  53.42%; FB1:  58.89  250\n",
      "              PER: precision:  72.07%; recall:  65.04%; FB1:  68.38  333\n",
      "(75.8, 61.57595450852965, 67.95159121470192)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: <unk> health began to <unk> in 0000 when she was <unk> with a heart <unk> .\n",
      "TRUE: O O O O O O O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O O\n",
      "SENT: The following table <unk> total flown air <unk> <unk> in tonnes <unk> at international German <unk> <unk> 0000 .\n",
      "TRUE: O O O O O O O O O O O O O O I-MISC O O O O\n",
      "PRED: O O O O O O O O O O O O O O I-MISC I-ORG I-ORG O O\n",
      "SENT: 10. <unk> <unk> ( Italy ) <unk> <unk> <unk>\n",
      "TRUE: O I-PER I-PER O I-LOC O I-MISC I-MISC O\n",
      "PRED: O I-PER I-PER O I-LOC O O O O\n",
      "SENT: The popular <unk> is playing his final major tournament next week and the <unk> champion 's Grand Slam <unk> could well be a <unk> <unk> .\n",
      "TRUE: O O I-MISC O O O O O O O O O O O O O I-MISC I-MISC O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O O I-MISC I-MISC O O O O O O O O\n",
      "SENT: An <unk> of <unk> has killed five people in the central Senegal town of <unk> , where health authorities have <unk> 0000 cases since August 0000 , a medical official said on Thursday .\n",
      "TRUE: O O O O O O O O O O O I-LOC O O I-LOC O O O O O O O O O O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "--- EPOCH 4 ---\n",
      "Avg loss over last 500 updates: 1.8024212040901184\n",
      "Avg loss over last 500 updates: 2.076576102018356\n",
      "Avg loss over last 500 updates: 1.7285114030838014\n",
      "Avg loss over last 500 updates: 1.7894728198051453\n",
      "Avg loss over last 500 updates: 1.4481688024997712\n",
      "Avg loss over last 500 updates: 1.7418981876373292\n",
      "Avg evaluation loss: 2.646669232696295\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1012 phrases; correct: 783.\n",
      "accuracy:  69.77%; (non-O)\n",
      "accuracy:  93.75%; precision:  77.37%; recall:  63.61%; FB1:  69.82\n",
      "              LOC: precision:  88.00%; recall:  72.73%; FB1:  79.64  300\n",
      "             MISC: precision:  80.00%; recall:  54.17%; FB1:  64.60  130\n",
      "              ORG: precision:  65.37%; recall:  54.72%; FB1:  59.57  257\n",
      "              PER: precision:  76.00%; recall:  66.94%; FB1:  71.18  325\n",
      "(77.37154150197628, 63.6068237205524, 69.81720909496211)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: SOCCER - <unk> <unk> <unk> <unk> .\n",
      "TRUE: O O I-ORG O O I-PER O\n",
      "PRED: O O O O O O O\n",
      "SENT: Pakistan , who <unk> next week , are the third team in the <unk> World Series tournament .\n",
      "TRUE: I-LOC O O O O O O O O O O O O O I-MISC I-MISC O O\n",
      "PRED: I-LOC O O O O O O O O O O O O O I-MISC I-MISC O O\n",
      "SENT: In San Diego , Steve <unk> and <unk> <unk> <unk> in three runs <unk> as the San Diego <unk> built a <unk> lead after three innings and <unk> to an <unk> victory over the Philadelphia <unk> .\n",
      "TRUE: O I-LOC I-LOC O I-PER I-PER O I-PER I-PER O O O O O O O I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O I-ORG I-ORG O\n",
      "PRED: O I-LOC I-LOC O I-PER I-PER O I-PER I-PER I-PER O O O O O O I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O I-ORG I-ORG O\n",
      "SENT: He said at one point during a press conference : \" I have seen my <unk> ( party manager ) for next week which , of course , does n't mean very much to me now . \"\n",
      "TRUE: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "SENT: - <unk> 0000 down <unk>\n",
      "TRUE: O I-LOC O O O\n",
      "PRED: O O O O O\n",
      "--- EPOCH 5 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss over last 500 updates: 1.5217311358451844\n",
      "Avg loss over last 500 updates: 1.7771587922573089\n",
      "Avg loss over last 500 updates: 1.4640770926475526\n",
      "Avg loss over last 500 updates: 1.5765903587341308\n",
      "Avg loss over last 500 updates: 1.27073810338974\n",
      "Avg loss over last 500 updates: 1.5173777339458465\n",
      "Avg evaluation loss: 2.666737079322338\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1080 phrases; correct: 817.\n",
      "accuracy:  72.47%; (non-O)\n",
      "accuracy:  93.86%; precision:  75.65%; recall:  66.37%; FB1:  70.71\n",
      "              LOC: precision:  89.63%; recall:  73.83%; FB1:  80.97  299\n",
      "             MISC: precision:  80.15%; recall:  54.69%; FB1:  65.02  131\n",
      "              ORG: precision:  64.86%; recall:  58.31%; FB1:  61.41  276\n",
      "              PER: precision:  70.86%; recall:  71.82%; FB1:  71.33  374\n",
      "(75.64814814814815, 66.36880584890334, 70.70532237126785)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: <unk> Windows 0000 sales fail to meet <unk> .\n",
      "TRUE: O I-MISC I-MISC O O O O O O\n",
      "PRED: I-MISC I-MISC O O O O O O O\n",
      "SENT: 0000 - <unk> Khan ( Pakistan ) beat Simon <unk> ( Germany ) 15-12 15-7 <unk> 15-10\n",
      "TRUE: O O I-PER I-PER O I-LOC O O I-PER I-PER O I-LOC O O O O O\n",
      "PRED: O O I-PER I-PER O I-LOC O O I-PER I-PER O I-LOC O O O O O\n",
      "SENT: -DOCSTART-\n",
      "TRUE: O\n",
      "PRED: O\n",
      "SENT: <unk> <unk> man takes slow train to <unk> .\n",
      "TRUE: O I-MISC O O O O O I-LOC O\n",
      "PRED: O O O O O O O O O\n",
      "SENT: <unk> that information about <unk> was \" as <unk> as the <unk> he <unk> \" , Jordan said he made some <unk> <unk> in the film .\n",
      "TRUE: O O O O I-PER O O O O O O O O O O O I-PER O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O O I-PER O O O O O O O O O O\n",
      "--- EPOCH 6 ---\n",
      "Avg loss over last 500 updates: 1.3447562766075134\n",
      "Avg loss over last 500 updates: 1.535671971797943\n",
      "Avg loss over last 500 updates: 1.3679579739570618\n",
      "Avg loss over last 500 updates: 1.3692223323583603\n",
      "Avg loss over last 500 updates: 1.1236593675613404\n",
      "Avg loss over last 500 updates: 1.3765277452468871\n",
      "Avg evaluation loss: 2.796843448057771\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1029 phrases; correct: 798.\n",
      "accuracy:  69.27%; (non-O)\n",
      "accuracy:  93.80%; precision:  77.55%; recall:  64.83%; FB1:  70.62\n",
      "              LOC: precision:  87.74%; recall:  74.93%; FB1:  80.83  310\n",
      "             MISC: precision:  78.20%; recall:  54.17%; FB1:  64.00  133\n",
      "              ORG: precision:  68.27%; recall:  55.37%; FB1:  61.15  249\n",
      "              PER: precision:  74.78%; recall:  68.29%; FB1:  71.39  337\n",
      "(77.55102040816327, 64.82534524776604, 70.61946902654867)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: <unk> sources said feed <unk> demand was keeping <unk> with <unk> production and driving prices higher .\n",
      "TRUE: I-LOC O O O O O O O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O O O\n",
      "SENT: <unk> <unk> <unk> ( Netherlands ) <unk> <unk>\n",
      "TRUE: O I-PER I-PER O I-LOC O I-ORG O\n",
      "PRED: O I-PER I-PER O I-LOC O O O\n",
      "SENT: USDA gross <unk> <unk> and <unk> value .\n",
      "TRUE: I-ORG O O O O O O O\n",
      "PRED: I-ORG O O O O O O O\n",
      "SENT: Gujral said India had national security <unk> that made it <unk> for New <unk> to sign the <unk> .\n",
      "TRUE: I-PER O I-LOC O O O O O O O O O I-LOC I-LOC O O O I-MISC O\n",
      "PRED: I-PER O I-LOC O O O O O O O O O I-LOC O O O O O O\n",
      "SENT: <unk> takes the <unk> on a trial basis , but new coach Glenn Hoddle said he saw no reason why the former Blackburn and <unk> <unk> should not make the post his own .\n",
      "TRUE: I-PER O O O O O O O O O O O I-PER I-PER O O O O O O O O I-ORG O I-ORG O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O I-PER I-PER O O O O O O O O I-ORG O I-PER I-PER O O O O O O O O\n",
      "--- EPOCH 7 ---\n",
      "Avg loss over last 500 updates: 1.3254957559108733\n",
      "Avg loss over last 500 updates: 1.4233969119787215\n",
      "Avg loss over last 500 updates: 1.1796032948493957\n",
      "Avg loss over last 500 updates: 1.2319926490783693\n",
      "Avg loss over last 500 updates: 1.1186067502498627\n",
      "Avg loss over last 500 updates: 1.3520136489868164\n",
      "Avg evaluation loss: 2.755386171862483\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1068 phrases; correct: 836.\n",
      "accuracy:  72.52%; (non-O)\n",
      "accuracy:  94.23%; precision:  78.28%; recall:  67.91%; FB1:  72.73\n",
      "              LOC: precision:  90.85%; recall:  76.58%; FB1:  83.11  306\n",
      "             MISC: precision:  83.21%; recall:  56.77%; FB1:  67.49  131\n",
      "              ORG: precision:  68.06%; recall:  58.31%; FB1:  62.81  263\n",
      "              PER: precision:  73.37%; recall:  73.17%; FB1:  73.27  368\n",
      "(78.27715355805243, 67.91226645004062, 72.72727272727273)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: James is a <unk> for a <unk> act of <unk> , while those who have done nothing for the cause are free , \" she <unk> .\n",
      "TRUE: I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "PRED: I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "SENT: <unk> of the fire has been <unk> because of the hot , <unk> , <unk> weather in the region , <unk> said .\n",
      "TRUE: O O O O O O O O O O O O O O O O O O O O I-PER O O\n",
      "PRED: O O O O O O O O O O O O O O O O O O O O I-PER O O\n",
      "SENT: One officer and a <unk> killed in <unk> clash between two groups of soldiers near <unk> in <unk> .\n",
      "TRUE: O O O O O O O O O O O O O O O I-LOC O I-LOC O\n",
      "PRED: O O O O O O O O O O O O O O O O O O O\n",
      "SENT: <unk> 0000\n",
      "TRUE: I-ORG I-ORG\n",
      "PRED: I-ORG O\n",
      "SENT: <unk> 0000 Lens 0000\n",
      "TRUE: I-ORG O I-ORG O\n",
      "PRED: I-ORG O I-ORG O\n",
      "--- EPOCH 8 ---\n",
      "Avg loss over last 500 updates: 1.1350729186534882\n",
      "Avg loss over last 500 updates: 1.2331692020893097\n",
      "Avg loss over last 500 updates: 1.1877408237457276\n",
      "Avg loss over last 500 updates: 1.1814506928920745\n",
      "Avg loss over last 500 updates: 0.882270970582962\n",
      "Avg loss over last 500 updates: 1.1948840792179107\n",
      "Avg evaluation loss: 2.761791606992483\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1094 phrases; correct: 833.\n",
      "accuracy:  73.02%; (non-O)\n",
      "accuracy:  93.97%; precision:  76.14%; recall:  67.67%; FB1:  71.66\n",
      "              LOC: precision:  87.03%; recall:  75.76%; FB1:  81.00  316\n",
      "             MISC: precision:  79.71%; recall:  57.29%; FB1:  66.67  138\n",
      "              ORG: precision:  65.80%; recall:  57.65%; FB1:  61.46  269\n",
      "              PER: precision:  73.05%; recall:  73.44%; FB1:  73.24  371\n",
      "(76.14259597806216, 67.66856214459789, 71.65591397849462)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: <unk> 0000 0000 0000 0000 0000 0000\n",
      "TRUE: I-ORG O O O O O O\n",
      "PRED: I-ORG O O O O O O\n",
      "SENT: <unk> <unk> <unk> ( Netherlands ) <unk> <unk>\n",
      "TRUE: O I-PER I-PER O I-LOC O I-ORG O\n",
      "PRED: I-PER I-PER I-PER O I-LOC O O O\n",
      "SENT: <unk> 0000 <unk> <unk> / <unk> <unk> <unk> .\n",
      "TRUE: I-ORG O O I-ORG O I-ORG O I-ORG O\n",
      "PRED: O O I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O\n",
      "SENT: 0000 - <unk> <unk>\n",
      "TRUE: O O O O\n",
      "PRED: O O I-PER I-PER\n",
      "SENT: 8. Michael <unk> ( Germany ) <unk>\n",
      "TRUE: O I-PER I-PER O I-LOC O O\n",
      "PRED: O I-PER I-PER O I-LOC O O\n",
      "--- EPOCH 9 ---\n",
      "Avg loss over last 500 updates: 0.9263007159233093\n",
      "Avg loss over last 500 updates: 1.1277051701545715\n",
      "Avg loss over last 500 updates: 1.0785345611572266\n",
      "Avg loss over last 500 updates: 1.0552179415225982\n",
      "Avg loss over last 500 updates: 0.859110579252243\n",
      "Avg loss over last 500 updates: 1.0179964146614076\n",
      "Avg evaluation loss: 2.769445691332221\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1164 phrases; correct: 854.\n",
      "accuracy:  75.83%; (non-O)\n",
      "accuracy:  93.96%; precision:  73.37%; recall:  69.37%; FB1:  71.32\n",
      "              LOC: precision:  86.88%; recall:  76.58%; FB1:  81.41  320\n",
      "             MISC: precision:  79.26%; recall:  55.73%; FB1:  65.44  135\n",
      "              ORG: precision:  60.13%; recall:  59.93%; FB1:  60.03  306\n",
      "              PER: precision:  70.72%; recall:  77.24%; FB1:  73.83  403\n",
      "(73.3676975945017, 69.37449228269699, 71.31524008350732)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: <unk> Prime Minister <unk> <unk> announced the <unk> poll on Thursday <unk> problems with the economy , the country 's <unk> with the European Union and <unk> relations with neighbouring Turkey .\n",
      "TRUE: O O O I-PER I-PER O O O O O O O O O O O O O O O O O O I-ORG I-ORG O O O O O I-LOC O\n",
      "PRED: O O O I-PER I-PER O O O O O O O O O O O O O O O O O O I-ORG I-ORG I-ORG I-ORG O O O I-LOC O\n",
      "SENT: COLORADO 0000 0000 <unk> 0000\n",
      "TRUE: I-ORG O O O O\n",
      "PRED: I-ORG O O O O\n",
      "SENT: <unk> <unk> 0000 <unk> <unk> 0000\n",
      "TRUE: I-ORG I-ORG O I-ORG I-ORG O\n",
      "PRED: I-ORG I-ORG O I-ORG I-ORG O\n",
      "SENT: \" I have to report this morning that we have in fact received reports ...\n",
      "TRUE: O O O O O O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O\n",
      "SENT: <unk> <unk> AT NEW YORK\n",
      "TRUE: I-ORG I-ORG O I-LOC I-LOC\n",
      "PRED: I-ORG I-ORG O I-LOC I-LOC\n",
      "--- EPOCH 10 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss over last 500 updates: 0.9659558396339416\n",
      "Avg loss over last 500 updates: 1.0577997666597367\n",
      "Avg loss over last 500 updates: 0.9794545738697052\n",
      "Avg loss over last 500 updates: 0.9344487383365631\n",
      "Avg loss over last 500 updates: 0.7893602849245072\n",
      "Avg loss over last 500 updates: 0.95338463139534\n",
      "Avg evaluation loss: 2.862163414210081\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1100 phrases; correct: 831.\n",
      "accuracy:  73.18%; (non-O)\n",
      "accuracy:  94.11%; precision:  75.55%; recall:  67.51%; FB1:  71.30\n",
      "              LOC: precision:  88.33%; recall:  77.13%; FB1:  82.35  317\n",
      "             MISC: precision:  77.94%; recall:  55.21%; FB1:  64.63  136\n",
      "              ORG: precision:  61.20%; recall:  59.61%; FB1:  60.40  299\n",
      "              PER: precision:  75.29%; recall:  71.00%; FB1:  73.08  348\n",
      "(75.54545454545455, 67.50609260763608, 71.29987129987131)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: A South African boy is writing back to an American girl whose message in a <unk> he found <unk> up on President Nelson <unk> 's <unk> prison island .\n",
      "TRUE: O I-MISC I-MISC O O O O O O I-MISC O O O O O O O O O O O O I-PER I-PER O O O O O\n",
      "PRED: O I-MISC I-MISC I-MISC O O O O O I-MISC O O O O O O O O O O O O I-PER I-PER O I-MISC O O O\n",
      "SENT: <unk> if we just wait another few years for the next <unk> in <unk> . \"\n",
      "TRUE: O O O O O O O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O I-LOC O O\n",
      "SENT: 5. <unk> <unk> ( Russia ) <unk>\n",
      "TRUE: O I-PER I-PER O I-LOC O O\n",
      "PRED: O I-PER I-PER O I-LOC O O\n",
      "SENT: <unk> 0000 ( <unk> <unk> , <unk> <unk> , <unk> 69th ) Freiburg 0000 .\n",
      "TRUE: I-LOC O O I-PER O O I-PER O O I-ORG O O I-LOC O O\n",
      "PRED: I-ORG O O I-PER I-PER O I-PER I-PER O I-PER O O I-ORG O O\n",
      "SENT: <unk> <unk> CUP <unk> RESULTS .\n",
      "TRUE: O I-MISC I-MISC O O O\n",
      "PRED: O I-MISC I-MISC O O O\n",
      "--- EPOCH 11 ---\n",
      "Avg loss over last 500 updates: 0.8050779192447662\n",
      "Avg loss over last 500 updates: 0.9753340170383453\n",
      "Avg loss over last 500 updates: 0.8691345720291138\n",
      "Avg loss over last 500 updates: 0.9070335071086884\n",
      "Avg loss over last 500 updates: 0.7293401705026626\n",
      "Avg loss over last 500 updates: 0.9080060286521912\n",
      "Avg evaluation loss: 2.992116259261966\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1080 phrases; correct: 846.\n",
      "accuracy:  72.08%; (non-O)\n",
      "accuracy:  94.24%; precision:  78.33%; recall:  68.72%; FB1:  73.22\n",
      "              LOC: precision:  89.84%; recall:  77.96%; FB1:  83.48  315\n",
      "             MISC: precision:  85.38%; recall:  57.81%; FB1:  68.94  130\n",
      "              ORG: precision:  68.12%; recall:  61.24%; FB1:  64.49  276\n",
      "              PER: precision:  73.54%; recall:  71.54%; FB1:  72.53  359\n",
      "(78.33333333333333, 68.72461413484972, 73.21505841627001)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: Men 's <unk> <unk> <unk> Owens <unk> race\n",
      "TRUE: O O O O I-PER I-PER O O\n",
      "PRED: O O O O I-PER I-PER O O\n",
      "SENT: <unk> - <unk> <unk> 1,000 <unk> <unk> .\n",
      "TRUE: O O I-PER O I-MISC I-MISC I-MISC O\n",
      "PRED: O O O O O O O O\n",
      "SENT: 0000 <unk> <unk> 0000 0000 0000 0000\n",
      "TRUE: O I-PER I-PER O O O O\n",
      "PRED: O I-ORG I-ORG O O O O\n",
      "SENT: Japanese <unk> of <unk> <unk> products in July <unk> <unk> percent over the same month last year to <unk> tonnes , while production rose <unk> percent to <unk> tonnes , according to preliminary data released on Tuesday by the Japan <unk> <unk> .\n",
      "TRUE: I-MISC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O I-ORG I-ORG I-ORG O\n",
      "PRED: I-MISC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O I-ORG I-ORG I-ORG O\n",
      "SENT: An <unk> of <unk> has killed five people in the central Senegal town of <unk> , where health authorities have <unk> 0000 cases since August 0000 , a medical official said on Thursday .\n",
      "TRUE: O O O O O O O O O O O I-LOC O O I-LOC O O O O O O O O O O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O I-MISC O O I-LOC O O O O O O O O O O O O O O O O O O O\n",
      "--- EPOCH 12 ---\n",
      "Avg loss over last 500 updates: 0.7910157408714295\n",
      "Avg loss over last 500 updates: 0.9120558997392655\n",
      "Avg loss over last 500 updates: 0.8174868822097778\n",
      "Avg loss over last 500 updates: 0.7868510890007019\n",
      "Avg loss over last 500 updates: 0.7127313309907913\n",
      "Avg loss over last 500 updates: 0.8579548659324646\n",
      "Avg evaluation loss: 3.100774076282978\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1064 phrases; correct: 838.\n",
      "accuracy:  71.92%; (non-O)\n",
      "accuracy:  94.25%; precision:  78.76%; recall:  68.07%; FB1:  73.03\n",
      "              LOC: precision:  89.81%; recall:  77.69%; FB1:  83.31  314\n",
      "             MISC: precision:  82.71%; recall:  57.29%; FB1:  67.69  133\n",
      "              ORG: precision:  66.92%; recall:  57.98%; FB1:  62.13  266\n",
      "              PER: precision:  76.35%; recall:  72.63%; FB1:  74.44  351\n",
      "(78.7593984962406, 68.07473598700243, 73.02832244008715)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: All <unk> 's Association secretary N.J. <unk> said the strike would continue <unk> and the fishermen would block road and rail traffic if their <unk> were not met .\n",
      "TRUE: I-ORG I-ORG I-ORG I-ORG O I-PER I-PER O O O O O O O O O O O O O O O O O O O O O O\n",
      "PRED: O I-PER O I-ORG O I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O\n",
      "SENT: <unk> Moody not out 0000\n",
      "TRUE: I-PER I-PER O O O\n",
      "PRED: O O O O O\n",
      "SENT: Extras ( <unk> <unk> <unk> <unk> ) 0000\n",
      "TRUE: O O O O O O O O\n",
      "PRED: O O O O O O O O\n",
      "SENT: What he did was bad for <unk> , bad for the crowd and bad for the sponsors .\n",
      "TRUE: O O O O O O O O O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O O O O\n",
      "SENT: <unk> 1996-12-06\n",
      "TRUE: I-LOC O\n",
      "PRED: I-LOC O\n",
      "--- EPOCH 13 ---\n",
      "Avg loss over last 500 updates: 0.7986461237668991\n",
      "Avg loss over last 500 updates: 0.8408407218456269\n",
      "Avg loss over last 500 updates: 0.7766634712219238\n",
      "Avg loss over last 500 updates: 0.8208987522125244\n",
      "Avg loss over last 500 updates: 0.6996162312030793\n",
      "Avg loss over last 500 updates: 0.8283475403785705\n",
      "Avg evaluation loss: 3.0596041445434095\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1145 phrases; correct: 852.\n",
      "accuracy:  74.17%; (non-O)\n",
      "accuracy:  94.15%; precision:  74.41%; recall:  69.21%; FB1:  71.72\n",
      "              LOC: precision:  89.06%; recall:  78.51%; FB1:  83.46  320\n",
      "             MISC: precision:  81.34%; recall:  56.77%; FB1:  66.87  134\n",
      "              ORG: precision:  58.15%; recall:  61.56%; FB1:  59.81  325\n",
      "              PER: precision:  73.50%; recall:  72.90%; FB1:  73.20  366\n",
      "(74.41048034934498, 69.21202274573518, 71.71717171717172)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: Following are key data from the August monthly <unk> of <unk> in UK <unk> by the Confederation of British Industry ( <unk> ) .\n",
      "TRUE: O O O O O O O O O O O O I-LOC O O O I-ORG I-ORG I-ORG I-ORG O I-ORG O O\n",
      "PRED: O O O O O O O O O O O O I-LOC O O O I-ORG I-ORG I-ORG I-ORG O I-ORG O O\n",
      "SENT: <unk> gave no <unk> that he had won any <unk> commitment from <unk> , the <unk> of the Bosnian Serbs , to <unk> any <unk> in the <unk> process .\n",
      "TRUE: I-PER O O O O O O O O O O O I-PER O O O O O I-MISC I-MISC O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O O O O I-MISC I-MISC O O O O O O O O O O\n",
      "SENT: -DOCSTART-\n",
      "TRUE: O\n",
      "PRED: O\n",
      "SENT: <unk> officials said the <unk> told authorities he <unk> the <unk> in his <unk> at home , but the <unk> recently broke down and the <unk> <unk> .\n",
      "TRUE: O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "PRED: I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "SENT: - Palestinian Minister <unk> says <unk> talks will begin by September 0000 .\n",
      "TRUE: O I-MISC O I-PER O I-MISC O O O O O O O\n",
      "PRED: O I-MISC O I-PER O O O O O O O O O\n",
      "--- EPOCH 14 ---\n",
      "Avg loss over last 500 updates: 0.6850141615867614\n",
      "Avg loss over last 500 updates: 0.8128684340715409\n",
      "Avg loss over last 500 updates: 0.7038701348304749\n",
      "Avg loss over last 500 updates: 0.7003347563743592\n",
      "Avg loss over last 500 updates: 0.6057291586399078\n",
      "Avg loss over last 500 updates: 0.7841927528381347\n",
      "Avg evaluation loss: 3.205224627703428\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1147 phrases; correct: 869.\n",
      "accuracy:  75.00%; (non-O)\n",
      "accuracy:  94.32%; precision:  75.76%; recall:  70.59%; FB1:  73.09\n",
      "              LOC: precision:  86.85%; recall:  78.24%; FB1:  82.32  327\n",
      "             MISC: precision:  84.96%; recall:  58.85%; FB1:  69.54  133\n",
      "              ORG: precision:  62.79%; recall:  61.56%; FB1:  62.17  301\n",
      "              PER: precision:  73.32%; recall:  76.69%; FB1:  74.97  386\n",
      "(75.76285963382738, 70.59301380991064, 73.08662741799832)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: David <unk> ( U.S. ) beat <unk> <unk> ( France ) 6-4 6-4\n",
      "TRUE: I-PER I-PER O I-LOC O O I-PER I-PER O I-LOC O O O\n",
      "PRED: I-PER I-PER O I-LOC O O I-PER I-PER O I-LOC O O O\n",
      "SENT: -DOCSTART-\n",
      "TRUE: O\n",
      "PRED: O\n",
      "SENT: 2. <unk> Sang ( Kenya ) <unk>\n",
      "TRUE: O I-PER I-PER O I-LOC O O\n",
      "PRED: O I-PER I-PER O I-LOC O O\n",
      "SENT: Pakistan , who <unk> next week , are the third team in the <unk> World Series tournament .\n",
      "TRUE: I-LOC O O O O O O O O O O O O O I-MISC I-MISC O O\n",
      "PRED: I-LOC O O O O O O O O O O O O I-MISC I-MISC I-MISC O O\n",
      "SENT: -DOCSTART-\n",
      "TRUE: O\n",
      "PRED: O\n",
      "--- EPOCH 15 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss over last 500 updates: 0.6162887995243073\n",
      "Avg loss over last 500 updates: 0.767611998796463\n",
      "Avg loss over last 500 updates: 0.7594582076072693\n",
      "Avg loss over last 500 updates: 0.7286020588874816\n",
      "Avg loss over last 500 updates: 0.6454344547986984\n",
      "Avg loss over last 500 updates: 0.7463096668720245\n",
      "Avg evaluation loss: 3.329512475579977\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1116 phrases; correct: 860.\n",
      "accuracy:  74.01%; (non-O)\n",
      "accuracy:  94.48%; precision:  77.06%; recall:  69.86%; FB1:  73.29\n",
      "              LOC: precision:  88.79%; recall:  78.51%; FB1:  83.33  321\n",
      "             MISC: precision:  78.17%; recall:  57.81%; FB1:  66.47  142\n",
      "              ORG: precision:  67.75%; recall:  60.91%; FB1:  64.15  276\n",
      "              PER: precision:  73.47%; recall:  75.07%; FB1:  74.26  377\n",
      "(77.06093189964157, 69.86190089358246, 73.28504473796335)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: JOHANNESBURG 1996-08-26\n",
      "TRUE: I-LOC O\n",
      "PRED: I-LOC O\n",
      "SENT: <unk> takes the <unk> on a trial basis , but new coach Glenn Hoddle said he saw no reason why the former Blackburn and <unk> <unk> should not make the post his own .\n",
      "TRUE: I-PER O O O O O O O O O O O I-PER I-PER O O O O O O O O I-ORG O I-ORG O O O O O O O O O\n",
      "PRED: I-PER O O O O O O O O O O O I-PER I-PER O O O O O O O O I-ORG O I-PER I-PER O O O O O O O O\n",
      "SENT: \" When this government <unk> on <unk> the peace process and <unk> it <unk> , this means that it is preparing for war , \" the radio said .\n",
      "TRUE: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "SENT: U.S. debt futures finished a <unk> <unk> session sharply lower , as the markets were <unk> by a stronger than expected rise in the August National Association of <unk> <unk> ( <unk> ) index for the Chicago area , traders and analysts said .\n",
      "TRUE: I-LOC O O O O O O O O O O O O O O O O O O O O O O O O I-ORG I-ORG I-ORG I-ORG I-ORG O I-ORG O O O O I-LOC O O O O O O O\n",
      "PRED: I-LOC O O O O O O O O O O O O O O O O O O O O O O O O I-ORG I-ORG I-ORG I-ORG I-ORG O I-ORG O O O O I-LOC O O O O O O O\n",
      "SENT: After I won I <unk> I could give them a little <unk> . \"\n",
      "TRUE: O O O O O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O\n",
      "--- EPOCH 16 ---\n",
      "Avg loss over last 500 updates: 0.6097680730819702\n",
      "Avg loss over last 500 updates: 0.7203723602294921\n",
      "Avg loss over last 500 updates: 0.6994125962257385\n",
      "Avg loss over last 500 updates: 0.6738083629608155\n",
      "Avg loss over last 500 updates: 0.5606578676700592\n",
      "Avg loss over last 500 updates: 0.765343980550766\n",
      "Avg evaluation loss: 3.436974233612418\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1138 phrases; correct: 863.\n",
      "accuracy:  74.67%; (non-O)\n",
      "accuracy:  94.21%; precision:  75.83%; recall:  70.11%; FB1:  72.86\n",
      "              LOC: precision:  88.47%; recall:  78.24%; FB1:  83.04  321\n",
      "             MISC: precision:  80.43%; recall:  57.81%; FB1:  67.27  138\n",
      "              ORG: precision:  65.61%; recall:  60.91%; FB1:  63.18  285\n",
      "              PER: precision:  71.32%; recall:  76.15%; FB1:  73.66  394\n",
      "(75.83479789103691, 70.10560519902518, 72.85774588433938)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: \" Now many Russian banks are strong and can make various <unk> of money <unk> , while <unk> traders are being ousted by more <unk> ones .\n",
      "TRUE: O O O I-MISC O O O O O O O O O O O O O O O O O O O O O O O\n",
      "PRED: O O O I-MISC O O O O O O O O O O O O O O O O O O O O O O O\n",
      "SENT: -DOCSTART-\n",
      "TRUE: O\n",
      "PRED: O\n",
      "SENT: -DOCSTART-\n",
      "TRUE: O\n",
      "PRED: O\n",
      "SENT: Pakistani bourse to use new <unk> index .\n",
      "TRUE: I-MISC O O O O O O O\n",
      "PRED: I-MISC O O O O I-MISC O O\n",
      "SENT: Queens Park Rangers 0000 0000 0000 0000 0000 0000 0000\n",
      "TRUE: I-ORG I-ORG I-ORG O O O O O O O\n",
      "PRED: I-ORG I-ORG I-ORG O O O O O O O\n",
      "--- EPOCH 17 ---\n",
      "Avg loss over last 500 updates: 0.6176106359958649\n",
      "Avg loss over last 500 updates: 0.6357658591270446\n",
      "Avg loss over last 500 updates: 0.7179370279312134\n",
      "Avg loss over last 500 updates: 0.6590957392454148\n",
      "Avg loss over last 500 updates: 0.5158558351993561\n",
      "Avg loss over last 500 updates: 0.6733847222328186\n",
      "Avg evaluation loss: 3.4848011322319508\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1172 phrases; correct: 860.\n",
      "accuracy:  75.17%; (non-O)\n",
      "accuracy:  94.07%; precision:  73.38%; recall:  69.86%; FB1:  71.58\n",
      "              LOC: precision:  88.27%; recall:  78.79%; FB1:  83.26  324\n",
      "             MISC: precision:  80.15%; recall:  56.77%; FB1:  66.46  136\n",
      "              ORG: precision:  63.49%; recall:  62.87%; FB1:  63.18  304\n",
      "              PER: precision:  66.67%; recall:  73.71%; FB1:  70.01  408\n",
      "(73.37883959044369, 69.86190089358246, 71.5771951727008)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: 1996-12-06\n",
      "TRUE: O\n",
      "PRED: O\n",
      "SENT: <unk> 1996-08-26\n",
      "TRUE: I-LOC O\n",
      "PRED: I-LOC O\n",
      "SENT: French shares ended <unk> weaker as <unk> about union <unk> <unk> for the <unk> and a weaker <unk> got the better of a <unk> rise on Wall Street .\n",
      "TRUE: I-MISC O O O O O O O O O O O O O O O O O O O O O O O O O I-LOC I-LOC O\n",
      "PRED: I-MISC O O O O O O O O O O O O O O O O O O O O O O O O O I-LOC I-LOC O\n",
      "SENT: MANCHESTER , England 1996-08-30\n",
      "TRUE: I-LOC O I-LOC O\n",
      "PRED: I-LOC O I-LOC O\n",
      "SENT: <unk> kills 0000 at <unk> <unk> <unk> .\n",
      "TRUE: O O O O I-MISC O O O\n",
      "PRED: O O O O O O O O\n",
      "--- EPOCH 18 ---\n",
      "Avg loss over last 500 updates: 0.5625086147785187\n",
      "Avg loss over last 500 updates: 0.6362532372474671\n",
      "Avg loss over last 500 updates: 0.6033770999908448\n",
      "Avg loss over last 500 updates: 0.6884403171539306\n",
      "Avg loss over last 500 updates: 0.5251422247886658\n",
      "Avg loss over last 500 updates: 0.6366876072883606\n",
      "Avg evaluation loss: 3.4858079870045184\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1153 phrases; correct: 879.\n",
      "accuracy:  75.22%; (non-O)\n",
      "accuracy:  94.30%; precision:  76.24%; recall:  71.41%; FB1:  73.74\n",
      "              LOC: precision:  89.54%; recall:  80.17%; FB1:  84.59  325\n",
      "             MISC: precision:  79.14%; recall:  57.29%; FB1:  66.47  139\n",
      "              ORG: precision:  65.13%; recall:  64.50%; FB1:  64.81  304\n",
      "              PER: precision:  72.73%; recall:  75.88%; FB1:  74.27  385\n",
      "(76.23590633130962, 71.40536149471974, 73.74161073825505)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: Queens Park Rangers 0000 0000 0000 0000 0000 0000 0000\n",
      "TRUE: I-ORG I-ORG I-ORG O O O O O O O\n",
      "PRED: I-ORG I-ORG I-ORG O O O O O O O\n",
      "SENT: U.S. debt futures finished a <unk> <unk> session sharply lower , as the markets were <unk> by a stronger than expected rise in the August National Association of <unk> <unk> ( <unk> ) index for the Chicago area , traders and analysts said .\n",
      "TRUE: I-LOC O O O O O O O O O O O O O O O O O O O O O O O O I-ORG I-ORG I-ORG I-ORG I-ORG O I-ORG O O O O I-LOC O O O O O O O\n",
      "PRED: I-LOC O O O O O O O O O O O O O O O O O O O O O O O O I-ORG I-ORG I-ORG I-ORG I-ORG O I-ORG O O O O I-LOC O O O O O O O\n",
      "SENT: Gujral said India had national security <unk> that made it <unk> for New <unk> to sign the <unk> .\n",
      "TRUE: I-PER O I-LOC O O O O O O O O O I-LOC I-LOC O O O I-MISC O\n",
      "PRED: I-PER O I-LOC O O O O O O O O O O O O O O I-MISC O\n",
      "SENT: Women 's <unk>\n",
      "TRUE: O O O\n",
      "PRED: O O O\n",
      "SENT: -DOCSTART-\n",
      "TRUE: O\n",
      "PRED: O\n",
      "--- EPOCH 19 ---\n",
      "Avg loss over last 500 updates: 0.5455642856359482\n",
      "Avg loss over last 500 updates: 0.6089283612966537\n",
      "Avg loss over last 500 updates: 0.638301130771637\n",
      "Avg loss over last 500 updates: 0.5788503661155701\n",
      "Avg loss over last 500 updates: 0.5540025676488877\n",
      "Avg loss over last 500 updates: 0.6498551986217499\n",
      "Avg evaluation loss: 3.7601016621291636\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1166 phrases; correct: 860.\n",
      "accuracy:  74.89%; (non-O)\n",
      "accuracy:  94.15%; precision:  73.76%; recall:  69.86%; FB1:  71.76\n",
      "              LOC: precision:  86.53%; recall:  79.61%; FB1:  82.93  334\n",
      "             MISC: precision:  80.74%; recall:  56.77%; FB1:  66.67  135\n",
      "              ORG: precision:  63.76%; recall:  59.61%; FB1:  61.62  287\n",
      "              PER: precision:  68.05%; recall:  75.61%; FB1:  71.63  410\n",
      "(73.75643224699829, 69.86190089358246, 71.75636211931581)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: Algerian security forces said in a statement that two people were killed and six were wounded when a <unk> bomb <unk> through a <unk> in the <unk> town of <unk> .\n",
      "TRUE: I-MISC O O O O O O O O O O O O O O O O O O O O O O O O O O O O I-LOC O\n",
      "PRED: I-MISC O O O O O O O O O O O O O O O O O O O O O O O O O O O O I-LOC O\n",
      "SENT: ATLANTA AT PITTSBURGH\n",
      "TRUE: I-ORG O I-LOC\n",
      "PRED: I-ORG O I-LOC\n",
      "SENT: The government said on Tuesday that the threat from a <unk> <unk> <unk> , while still <unk> <unk> , <unk> to be <unk> in the western Japan city of <unk> , where the epidemic hit the <unk> .\n",
      "TRUE: O O O O O O O O O O O O O O O O O O O O O O O O O O I-LOC O O I-LOC O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O O O O O O O O O O O O I-LOC O O I-LOC O O O O O O O O\n",
      "SENT: More <unk> results are expected soon .\n",
      "TRUE: O O O O O O O\n",
      "PRED: O O O O O O O\n",
      "SENT: Figures were as <unk> ( in tonnes ) :\n",
      "TRUE: O O O O O O O O O\n",
      "PRED: O O O O O O O O O\n",
      "--- EPOCH 20 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss over last 500 updates: 0.5034690554141998\n",
      "Avg loss over last 500 updates: 0.6584479374885559\n",
      "Avg loss over last 500 updates: 0.5673298053741455\n",
      "Avg loss over last 500 updates: 0.5480854783058167\n",
      "Avg loss over last 500 updates: 0.44632628536224367\n",
      "Avg loss over last 500 updates: 0.5934395396709442\n",
      "Avg evaluation loss: 3.641953550577164\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1208 phrases; correct: 881.\n",
      "accuracy:  75.99%; (non-O)\n",
      "accuracy:  94.06%; precision:  72.93%; recall:  71.57%; FB1:  72.24\n",
      "              LOC: precision:  85.59%; recall:  81.82%; FB1:  83.66  347\n",
      "             MISC: precision:  79.17%; recall:  59.38%; FB1:  67.86  144\n",
      "              ORG: precision:  63.33%; recall:  61.89%; FB1:  62.60  300\n",
      "              PER: precision:  67.15%; recall:  75.88%; FB1:  71.25  417\n",
      "(72.93046357615894, 71.56783103168156, 72.24272242722428)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: <unk> officials said the <unk> told authorities he <unk> the <unk> in his <unk> at home , but the <unk> recently broke down and the <unk> <unk> .\n",
      "TRUE: O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "PRED: I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "SENT: It was <unk> to reporters at the press centre of Clinton 's Democratic convention headquarters just hours before the president was to address the delegates <unk> the party 's nomination for a second <unk> term in the White House .\n",
      "TRUE: O O O O O O O O O O I-PER O I-MISC O O O O O O O O O O O O O O O O O O O O O O O O I-LOC I-LOC O\n",
      "PRED: O O O O O O O O O O I-PER O I-MISC O O O O O O O O O O O O O O O O O O O O O O O O I-LOC I-LOC O\n",
      "SENT: <unk> Scott <unk> 0000 0000\n",
      "TRUE: O I-PER I-PER O O\n",
      "PRED: I-PER I-PER I-PER O O\n",
      "SENT: <unk> president <unk> Meri won 0000 votes compared to 0000 won by his rival , <unk> <unk> <unk> <unk> Ruutel .\n",
      "TRUE: O O I-PER I-PER O O O O O O O O O O O O O O I-PER I-PER O\n",
      "PRED: O O I-PER I-PER O O O O O O O O O O O I-PER I-PER I-PER I-PER I-PER O\n",
      "SENT: Last year , Martinez , who finished 0000 <unk> second in the world , reached the <unk> before <unk> out to Monica Seles .\n",
      "TRUE: O O O I-PER O O O O O O O O O O O O O O O O O I-PER I-PER O\n",
      "PRED: O O O I-PER O O O O O O O O O O O O O O O O O I-PER I-PER O\n",
      "--- EPOCH 21 ---\n",
      "Avg loss over last 500 updates: 0.5093656554222107\n",
      "Avg loss over last 500 updates: 0.6417726759910584\n",
      "Avg loss over last 500 updates: 0.5481071362495422\n",
      "Avg loss over last 500 updates: 0.5392106400728226\n",
      "Avg loss over last 500 updates: 0.4878001706600189\n",
      "Avg loss over last 500 updates: 0.5262267644405365\n",
      "Avg evaluation loss: 3.6228024417161944\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1183 phrases; correct: 872.\n",
      "accuracy:  75.72%; (non-O)\n",
      "accuracy:  94.20%; precision:  73.71%; recall:  70.84%; FB1:  72.25\n",
      "              LOC: precision:  88.13%; recall:  81.82%; FB1:  84.86  337\n",
      "             MISC: precision:  74.17%; recall:  58.33%; FB1:  65.31  151\n",
      "              ORG: precision:  61.22%; recall:  62.21%; FB1:  61.71  312\n",
      "              PER: precision:  71.02%; recall:  73.71%; FB1:  72.34  383\n",
      "(73.71090448013526, 70.83671811535336, 72.24523612261807)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: A South African boy is writing back to an American girl whose message in a <unk> he found <unk> up on President Nelson <unk> 's <unk> prison island .\n",
      "TRUE: O I-MISC I-MISC O O O O O O I-MISC O O O O O O O O O O O O I-PER I-PER O O O O O\n",
      "PRED: I-MISC I-MISC I-MISC O O O O O O I-MISC O O O O O O O O O O O O I-PER I-PER O I-MISC O O O\n",
      "SENT: 14. <unk> 0000 0000 - 0000 0000 0000 0000\n",
      "TRUE: O I-ORG O O O O O O O\n",
      "PRED: O I-ORG O O O O O O O\n",
      "SENT: <unk> <unk> CUP <unk> RESULTS .\n",
      "TRUE: O I-MISC I-MISC O O O\n",
      "PRED: I-MISC I-MISC I-MISC O O O\n",
      "SENT: The government said on Tuesday that the threat from a <unk> <unk> <unk> , while still <unk> <unk> , <unk> to be <unk> in the western Japan city of <unk> , where the epidemic hit the <unk> .\n",
      "TRUE: O O O O O O O O O O O O O O O O O O O O O O O O O O I-LOC O O I-LOC O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O O O O O O O O O O O O I-LOC O O I-LOC O O O O O O O O\n",
      "SENT: She is <unk> but her breathing is <unk> . \"\n",
      "TRUE: O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O\n",
      "--- EPOCH 22 ---\n",
      "Avg loss over last 500 updates: 0.4765153954029083\n",
      "Avg loss over last 500 updates: 0.5954650101661683\n",
      "Avg loss over last 500 updates: 0.6043393397331238\n",
      "Avg loss over last 500 updates: 0.5019165916442871\n",
      "Avg loss over last 500 updates: 0.3930429489612579\n",
      "Avg loss over last 500 updates: 0.49574832010269165\n",
      "Avg evaluation loss: 3.8234318105876444\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1163 phrases; correct: 873.\n",
      "accuracy:  75.55%; (non-O)\n",
      "accuracy:  94.33%; precision:  75.06%; recall:  70.92%; FB1:  72.93\n",
      "              LOC: precision:  89.41%; recall:  79.06%; FB1:  83.92  321\n",
      "             MISC: precision:  76.92%; recall:  57.29%; FB1:  65.67  143\n",
      "              ORG: precision:  66.19%; recall:  60.59%; FB1:  63.27  281\n",
      "              PER: precision:  69.38%; recall:  78.59%; FB1:  73.70  418\n",
      "(75.06448839208943, 70.91795288383427, 72.93233082706767)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: The September Treasury bond future on the Chicago Board of Trade was trading at <unk> , down <unk> from Thursday 's settlement price .\n",
      "TRUE: O O I-ORG O O O O I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O\n",
      "PRED: O O I-ORG O O O O I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O\n",
      "SENT: -DOCSTART-\n",
      "TRUE: O\n",
      "PRED: O\n",
      "SENT: <unk> <unk> , deposed leader of the Indonesian Democratic Party ( <unk> ) has <unk> the government for <unk> her as <unk> leader .\n",
      "TRUE: I-PER I-PER O O O O O I-ORG I-ORG I-ORG O I-ORG O O O O O O O O O I-ORG O O\n",
      "PRED: I-PER I-PER O O O O O I-ORG I-ORG I-ORG O I-ORG O O O O O O O O O O O O\n",
      "SENT: \" It will give the fans something <unk> to look at <unk> his <unk> . \"\n",
      "TRUE: O O O O O O O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O O\n",
      "SENT: <unk>\n",
      "TRUE: O\n",
      "PRED: O\n",
      "--- EPOCH 23 ---\n",
      "Avg loss over last 500 updates: 0.4383860890865326\n",
      "Avg loss over last 500 updates: 0.49142834496498106\n",
      "Avg loss over last 500 updates: 0.5720186510086059\n",
      "Avg loss over last 500 updates: 0.494691148519516\n",
      "Avg loss over last 500 updates: 0.4376022324562073\n",
      "Avg loss over last 500 updates: 0.5067327675819397\n",
      "Avg evaluation loss: 3.7273299933969977\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1171 phrases; correct: 884.\n",
      "accuracy:  75.88%; (non-O)\n",
      "accuracy:  94.40%; precision:  75.49%; recall:  71.81%; FB1:  73.61\n",
      "              LOC: precision:  86.39%; recall:  80.44%; FB1:  83.31  338\n",
      "             MISC: precision:  80.14%; recall:  58.85%; FB1:  67.87  141\n",
      "              ORG: precision:  67.03%; recall:  60.26%; FB1:  63.46  276\n",
      "              PER: precision:  70.67%; recall:  79.67%; FB1:  74.90  416\n",
      "(75.49103330486764, 71.81153533712428, 73.60532889258951)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: Italy <unk> <unk> Cuttitta\n",
      "TRUE: I-LOC O I-PER I-PER\n",
      "PRED: I-LOC O I-PER I-PER\n",
      "SENT: There is nothing left for us but to be <unk> to <unk> for <unk> <unk> , \" <unk> <unk> said .\n",
      "TRUE: O O O O O O O O O O O O O O O O O I-ORG I-ORG O O\n",
      "PRED: O O O O O O O O O O O O O O O O O I-PER I-PER O O\n",
      "SENT: LONDON 1996-08-22\n",
      "TRUE: I-LOC O\n",
      "PRED: I-LOC O\n",
      "SENT: When we <unk> the shares we <unk> ...\n",
      "TRUE: O O O O O O O O\n",
      "PRED: O O O O O O O O\n",
      "SENT: \" He 's a <unk> and a <unk> , but he <unk> the <unk> between a <unk> <unk> and an <unk> .\n",
      "TRUE: O O O O O O O O O O O O O O O O I-MISC O O O I-MISC O\n",
      "PRED: O O O O O O O O O O O O O O O O O O O O O O\n",
      "--- EPOCH 24 ---\n",
      "Avg loss over last 500 updates: 0.4790701217651367\n",
      "Avg loss over last 500 updates: 0.4979707100391388\n",
      "Avg loss over last 500 updates: 0.48168832206726075\n",
      "Avg loss over last 500 updates: 0.4400725684165955\n",
      "Avg loss over last 500 updates: 0.4453051578998566\n",
      "Avg loss over last 500 updates: 0.5280742192268372\n",
      "Avg evaluation loss: 3.72794287070632\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1159 phrases; correct: 869.\n",
      "accuracy:  74.50%; (non-O)\n",
      "accuracy:  94.15%; precision:  74.98%; recall:  70.59%; FB1:  72.72\n",
      "              LOC: precision:  88.72%; recall:  80.17%; FB1:  84.23  328\n",
      "             MISC: precision:  80.99%; recall:  59.90%; FB1:  68.86  142\n",
      "              ORG: precision:  60.82%; recall:  63.19%; FB1:  61.98  319\n",
      "              PER: precision:  72.70%; recall:  72.90%; FB1:  72.80  370\n",
      "(74.97842968075928, 70.59301380991064, 72.71966527196653)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: <unk> were <unk> in the money market but <unk> in bonds .\n",
      "TRUE: O O O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O\n",
      "SENT: - <unk> <unk> of law violation incidents -- which <unk> in the <unk> Lebanon elections last Sunday .\n",
      "TRUE: O O O O O O O O O O O O I-LOC I-LOC O O O O\n",
      "PRED: O I-PER O O O O O O O O O O O I-LOC O O O O\n",
      "SENT: <unk> <unk> CUP <unk> RESULTS .\n",
      "TRUE: O I-MISC I-MISC O O O\n",
      "PRED: O I-MISC I-MISC O O O\n",
      "SENT: Johnson said that <unk> interest rates have already been <unk> by the election .\n",
      "TRUE: I-PER O O O O O O O O O O O O O\n",
      "PRED: I-PER O O O O O O O O O O O O O\n",
      "SENT: SOCCER - <unk> FIRST DIVISION RESULTS .\n",
      "TRUE: O O I-MISC O O O O\n",
      "PRED: O O I-LOC O O O O\n",
      "--- EPOCH 25 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss over last 500 updates: 0.4804385347366333\n",
      "Avg loss over last 500 updates: 0.6397465682029724\n",
      "Avg loss over last 500 updates: 0.45741422080993654\n",
      "Avg loss over last 500 updates: 0.4297875633239746\n",
      "Avg loss over last 500 updates: 0.4302713652849197\n",
      "Avg loss over last 500 updates: 0.47046397495269776\n",
      "Avg evaluation loss: 3.839851883724332\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1163 phrases; correct: 869.\n",
      "accuracy:  74.61%; (non-O)\n",
      "accuracy:  94.15%; precision:  74.72%; recall:  70.59%; FB1:  72.60\n",
      "              LOC: precision:  86.09%; recall:  81.82%; FB1:  83.90  345\n",
      "             MISC: precision:  86.05%; recall:  57.81%; FB1:  69.16  129\n",
      "              ORG: precision:  62.84%; recall:  60.59%; FB1:  61.69  296\n",
      "              PER: precision:  69.97%; recall:  74.53%; FB1:  72.18  393\n",
      "(74.72055030094583, 70.59301380991064, 72.59816207184629)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: <unk> <unk> <unk> ( France ) 0000\n",
      "TRUE: O I-PER I-PER O I-LOC O O\n",
      "PRED: I-PER I-PER I-PER O I-LOC O O\n",
      "SENT: Following are some of the main stories in Tuesday 's Sri Lankan newspapers :\n",
      "TRUE: O O O O O O O O O O I-MISC I-MISC O O\n",
      "PRED: O O O O O O O O O O I-MISC I-MISC O O\n",
      "SENT: <unk> said <unk> will begin and revenue will start to <unk> in during the first half of next year .\n",
      "TRUE: I-PER O O O O O O O O O O O O O O O O O O O\n",
      "PRED: I-PER O I-PER O O O O O O O O O O O O O O O O O\n",
      "SENT: Aberdeen v Hearts\n",
      "TRUE: I-ORG O I-ORG\n",
      "PRED: I-ORG O I-ORG\n",
      "SENT: Scores : Australia <unk> in 0000 overs , Sri Lanka <unk> in <unk> overs .\n",
      "TRUE: O O I-LOC O O O O O I-LOC I-LOC O O O O O\n",
      "PRED: O O I-LOC O O O O O I-LOC I-LOC O O O O O\n",
      "--- EPOCH 26 ---\n",
      "Avg loss over last 500 updates: 0.46381522274017334\n",
      "Avg loss over last 500 updates: 0.4685400426387787\n",
      "Avg loss over last 500 updates: 0.44418631434440614\n",
      "Avg loss over last 500 updates: 0.4826257905960083\n",
      "Avg loss over last 500 updates: 0.33751558542251586\n",
      "Avg loss over last 500 updates: 0.4764733304977417\n",
      "Avg evaluation loss: 4.119030478298664\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1163 phrases; correct: 875.\n",
      "accuracy:  74.50%; (non-O)\n",
      "accuracy:  94.23%; precision:  75.24%; recall:  71.08%; FB1:  73.10\n",
      "              LOC: precision:  85.23%; recall:  82.64%; FB1:  83.92  352\n",
      "             MISC: precision:  85.50%; recall:  58.33%; FB1:  69.35  131\n",
      "              ORG: precision:  68.48%; recall:  57.33%; FB1:  62.41  257\n",
      "              PER: precision:  67.85%; recall:  77.78%; FB1:  72.47  423\n",
      "(75.23645743766122, 71.0804224207961, 73.09941520467837)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: Following are some of the main stories in Tuesday 's Sri Lankan newspapers :\n",
      "TRUE: O O O O O O O O O O I-MISC I-MISC O O\n",
      "PRED: O O O O O O O O O O I-MISC I-MISC O O\n",
      "SENT: A South African boy is writing back to an American girl whose message in a <unk> he found <unk> up on President Nelson <unk> 's <unk> prison island .\n",
      "TRUE: O I-MISC I-MISC O O O O O O I-MISC O O O O O O O O O O O O I-PER I-PER O O O O O\n",
      "PRED: O I-MISC I-MISC O O O O O O O O O O O O O O O O O O O I-PER I-PER O I-MISC O O O\n",
      "SENT: <unk> only hours after Chinese state media said the time was right to <unk> in political talks with Taiwan , Foreign Ministry spokesman <unk> <unk> told Reuters : \" The <unk> <unk> for the opening of the talks has been <unk> by the Taiwan authorities . \"\n",
      "TRUE: O O O O I-MISC O O O O O O O O O O O O O I-LOC O I-ORG I-ORG O I-PER I-PER O I-ORG O O O O O O O O O O O O O O O O I-LOC O O O\n",
      "PRED: O O O O I-MISC O O O O O O O O O O O O O I-LOC O O O O I-PER I-PER O I-ORG O O O O O O O O O O O O O O O O I-LOC O O O\n",
      "SENT: In the <unk> , between 0000 to 0000 percent of the muscle <unk> in one group of <unk> produced <unk> for two weeks before <unk> .\n",
      "TRUE: O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "SENT: Bank of New Zealand said on Thursday it was <unk> its <unk> home lending rates .\n",
      "TRUE: I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O\n",
      "PRED: I-ORG O I-LOC I-LOC O O O O O O O O O O O O\n",
      "--- EPOCH 27 ---\n",
      "Avg loss over last 500 updates: 0.44169418668746946\n",
      "Avg loss over last 500 updates: 0.4987343411445618\n",
      "Avg loss over last 500 updates: 0.5123450204133987\n",
      "Avg loss over last 500 updates: 0.39099076473712924\n",
      "Avg loss over last 500 updates: 0.3112897576093674\n",
      "Avg loss over last 500 updates: 0.4719349846839905\n",
      "Avg evaluation loss: 3.885936437100172\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1170 phrases; correct: 882.\n",
      "accuracy:  75.88%; (non-O)\n",
      "accuracy:  94.25%; precision:  75.38%; recall:  71.65%; FB1:  73.47\n",
      "              LOC: precision:  85.55%; recall:  81.54%; FB1:  83.50  346\n",
      "             MISC: precision:  79.31%; recall:  59.90%; FB1:  68.25  145\n",
      "              ORG: precision:  64.51%; recall:  61.56%; FB1:  63.00  293\n",
      "              PER: precision:  73.06%; recall:  76.42%; FB1:  74.70  386\n",
      "(75.38461538461539, 71.64906580016248, 73.46938775510205)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: <unk> <unk> <unk> said on Thursday it will <unk> its cash <unk> rate for the October <unk> <unk> , <unk> continued <unk> results .\n",
      "TRUE: I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O\n",
      "PRED: I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O\n",
      "SENT: \" Now many Russian banks are strong and can make various <unk> of money <unk> , while <unk> traders are being ousted by more <unk> ones .\n",
      "TRUE: O O O I-MISC O O O O O O O O O O O O O O O O O O O O O O O\n",
      "PRED: O O O I-MISC O O O O O O O O O O O O O I-LOC O O O O O O O O O\n",
      "SENT: -DOCSTART-\n",
      "TRUE: O\n",
      "PRED: O\n",
      "SENT: NAC Breda 0000 Sparta Rotterdam 0000\n",
      "TRUE: I-ORG I-ORG O I-ORG I-ORG O\n",
      "PRED: I-ORG I-ORG O I-ORG I-ORG O\n",
      "SENT: The defeat put the <unk> out of the <unk> Cup .\n",
      "TRUE: O O O O I-MISC O O O I-MISC I-MISC O\n",
      "PRED: O O O O O O O O I-MISC I-MISC O\n",
      "--- EPOCH 28 ---\n",
      "Avg loss over last 500 updates: 0.45649770653247834\n",
      "Avg loss over last 500 updates: 0.479700732588768\n",
      "Avg loss over last 500 updates: 0.4629496941566467\n",
      "Avg loss over last 500 updates: 0.46792813873291017\n",
      "Avg loss over last 500 updates: 0.3523221753835678\n",
      "Avg loss over last 500 updates: 0.37225116086006166\n",
      "Avg evaluation loss: 3.900624142512679\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1168 phrases; correct: 876.\n",
      "accuracy:  75.39%; (non-O)\n",
      "accuracy:  94.40%; precision:  75.00%; recall:  71.16%; FB1:  73.03\n",
      "              LOC: precision:  86.69%; recall:  80.72%; FB1:  83.59  338\n",
      "             MISC: precision:  76.71%; recall:  58.33%; FB1:  66.27  146\n",
      "              ORG: precision:  66.90%; recall:  62.54%; FB1:  64.65  287\n",
      "              PER: precision:  70.28%; recall:  75.61%; FB1:  72.85  397\n",
      "(75.0, 71.16165718927701, 73.03042934556065)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: <unk> :\n",
      "TRUE: O O\n",
      "PRED: O O\n",
      "SENT: COLOMBO 1996-08-30\n",
      "TRUE: I-LOC O\n",
      "PRED: I-LOC O\n",
      "SENT: 5. Van <unk> 0000\n",
      "TRUE: O I-PER I-PER O\n",
      "PRED: O I-PER I-PER O\n",
      "SENT: 1996-12-06\n",
      "TRUE: O\n",
      "PRED: O\n",
      "SENT: R. Croft not out 0000\n",
      "TRUE: I-PER I-PER O O O\n",
      "PRED: I-PER I-PER O O O\n",
      "--- EPOCH 29 ---\n",
      "Avg loss over last 500 updates: 0.41261683440208435\n",
      "Avg loss over last 500 updates: 0.4618697001934052\n",
      "Avg loss over last 500 updates: 0.49266003251075746\n",
      "Avg loss over last 500 updates: 0.34984651148319246\n",
      "Avg loss over last 500 updates: 0.31520017218589785\n",
      "Avg loss over last 500 updates: 0.38851754283905027\n",
      "Avg evaluation loss: 4.089232437610626\n",
      "I am here bc\n",
      "processed 11170 tokens with 1231 phrases; found: 1199 phrases; correct: 869.\n",
      "accuracy:  75.17%; (non-O)\n",
      "accuracy:  93.93%; precision:  72.48%; recall:  70.59%; FB1:  71.52\n",
      "              LOC: precision:  88.00%; recall:  78.79%; FB1:  83.14  325\n",
      "             MISC: precision:  77.08%; recall:  57.81%; FB1:  66.07  144\n",
      "              ORG: precision:  56.23%; recall:  63.19%; FB1:  59.51  345\n",
      "              PER: precision:  72.21%; recall:  75.34%; FB1:  73.74  385\n",
      "(72.47706422018348, 70.59301380991064, 71.52263374485597)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: <unk> <unk> <unk> of South Africa defeated Tim <unk> of Britain 6-4 6-4 after a <unk> evening rain <unk> and <unk> Thomas <unk> of Sweden won his <unk> match , <unk> Petr <unk> of the Czech Republic 6-3 6-4 .\n",
      "TRUE: O I-PER I-PER O I-LOC I-LOC O I-PER I-PER O I-LOC O O O O O O O O O O I-PER I-PER O I-LOC O O O O O O I-PER I-PER O O I-LOC I-LOC O O O\n",
      "PRED: O I-PER I-PER O I-LOC I-LOC O I-PER I-PER O I-LOC O O O O O O O O O O I-PER I-PER O I-LOC O O O O O O I-PER I-PER O O I-LOC I-LOC O O O\n",
      "SENT: -- Bangkok newsroom <unk>\n",
      "TRUE: O I-LOC O O\n",
      "PRED: O I-MISC O O\n",
      "SENT: Iran <unk> <unk> <unk> Iran\n",
      "TRUE: I-MISC I-MISC O O I-LOC\n",
      "PRED: I-LOC O O O I-LOC\n",
      "SENT: 6. Michael <unk> ( U.S. ) <unk>\n",
      "TRUE: O I-PER I-PER O I-LOC O O\n",
      "PRED: O I-PER I-PER O I-LOC O O\n",
      "SENT: As often , the most volume was in <unk> .\n",
      "TRUE: O O O O O O O O I-ORG O\n",
      "PRED: O O O O O O O O O O\n"
     ]
    }
   ],
   "source": [
    "# Train BiLSTM Tagger Baseline\n",
    "if model_name == 'crf':\n",
    "  model = BiLSTMCRFTagger(len(word_vocab), len(label_vocab), 128, 256).to(device)\n",
    "else:\n",
    "  model = BiLSTMTagger(len(word_vocab), len(label_vocab), 128, 256).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "train(model, train_data, valid_data, word_vocab, label_vocab, model_name, epochs=30, log_interval=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving losses and plotting the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "oXDQ5cN_gfcn"
   },
   "outputs": [],
   "source": [
    "## Saving losses\n",
    "import pickle\n",
    "with open('loss_dict_crf.pkl','wb') as write_file:\n",
    "    pickle.dump([training_loss_dict,validation_loss_dict], write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "5xD8cm-vgfcn",
    "outputId": "6cb59f6f-0246-4769-de2f-93b3f5b430aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f97982ed550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the graph\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data = pickle.load(open('logs/loss_dict_crf.pkl','rb'))\n",
    "## Plotting loss epoch  wise\n",
    "\n",
    "\n",
    "epochs_to_plot = 30\n",
    "train_loss = data[0][:epochs_to_plot]\n",
    "valid_loss = data[1][:epochs_to_plot]\n",
    "epoch_num = list(range(1,len(train_loss)+1))[:epochs_to_plot]\n",
    "input_ticks = [i for i in range(30) if i%2==0]\n",
    "plt.title(\"Train and val loss CRF Model\")\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks(input_ticks, input_ticks)\n",
    "#plt.ylim(4,8)\n",
    "plt.plot(epoch_num, train_loss, label='Train loss')\n",
    "plt.plot(epoch_num, valid_loss, label='Val loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9768e74240>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the graph\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data = pickle.load(open('logs/loss_dict_crf.pkl','rb'))\n",
    "data_base = pickle.load(open('logs/loss_dict_trad.pkl','rb'))\n",
    "## Plotting loss epoch  wise\n",
    "\n",
    "\n",
    "epochs_to_plot = 30\n",
    "train_loss = data[0][:epochs_to_plot]\n",
    "valid_loss = data[1][:epochs_to_plot]\n",
    "train_loss_base = data_base[0][:epochs_to_plot]\n",
    "valid_loss_base = data_base[1][:epochs_to_plot]\n",
    "epoch_num = list(range(1,len(train_loss)+1))[:epochs_to_plot]\n",
    "input_ticks = [i for i in range(30) if i%2==0]\n",
    "plt.title(\"Train and val loss for CRF and baseline Model\")\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks(input_ticks, input_ticks)\n",
    "#plt.ylim(4,8)\n",
    "plt.plot(epoch_num, train_loss, label='Train Loss CRF')\n",
    "plt.plot(epoch_num, valid_loss, label='Val loss CRF')\n",
    "plt.plot(epoch_num, train_loss_base, label='Train loss Base')\n",
    "plt.plot(epoch_num, valid_loss_base, label='Val loss Base')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Y7O_3rjLWdE"
   },
   "source": [
    "### Parsing the log files for precision, recall, FB1. Plotting them later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_open = open('logs/result_crf.txt', 'r').readlines()\n",
    "num_lines_crf = len(file_open)\n",
    "precision_crf = []\n",
    "recall_crf = []\n",
    "f1_crf = []\n",
    "non_o_acc_crf = []\n",
    "total_acc_crf = []\n",
    "\n",
    "for i in range(0, num_lines_crf, 6):\n",
    "    last_line = file_open[i + 5].strip().split(\"\\t\")\n",
    "    precision_crf.append(float(last_line[0]))\n",
    "    recall_crf.append(float(last_line[1]))\n",
    "    f1_crf.append(float(last_line[2]))\n",
    "    first_line = file_open[i].strip().split(\"\\t\")\n",
    "    non_o_acc_crf.append(float(first_line[4]))\n",
    "    total_acc_crf.append(float(first_line[5]))\n",
    "    \n",
    "\n",
    "file_open = open('logs/result_trad.txt', 'r').readlines()\n",
    "num_lines_trad = len(file_open)\n",
    "precision_trad = []\n",
    "recall_trad = []\n",
    "f1_trad = []\n",
    "non_o_acc_trad = []\n",
    "total_acc_trad = []\n",
    "\n",
    "for i in range(0, num_lines_trad, 6):\n",
    "    last_line = file_open[i + 5].strip().split(\"\\t\")\n",
    "    precision_trad.append(float(last_line[0]))\n",
    "    recall_trad.append(float(last_line[1]))\n",
    "    f1_trad.append(float(last_line[2]))\n",
    "    first_line = file_open[i].strip().split(\"\\t\")\n",
    "    non_o_acc_trad.append(float(first_line[4]))\n",
    "    total_acc_trad.append(float(first_line[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f95bb689320>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs_to_plot = 30\n",
    "crf_f1 = recall_crf[:epochs_to_plot]\n",
    "trad_f1 = recall_trad[:epochs_to_plot]\n",
    "epoch_num = list(range(1,len(crf_f1)+1))[:epochs_to_plot]\n",
    "input_ticks = [i for i in range(31) if i%2==0]\n",
    "plt.title(\"Recall for CRF vs Baseline Model\")\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.xticks(input_ticks, input_ticks)\n",
    "plt.ylim(40,90)\n",
    "plt.plot(epoch_num, crf_f1, label='CRF')\n",
    "plt.plot(epoch_num, trad_f1, label='Baseline')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Calculation for span and token level results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modify the evaluate function to get token levekl results as well\n",
    "\n",
    "def evaluate_test(model, dataset, word_vocab, label_vocab, model_name):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    scores = []\n",
    "    true_tags = []\n",
    "    pred_tags = []\n",
    "    sents = []\n",
    "    for i, (sent, tags) in enumerate(dataset):\n",
    "        with torch.no_grad():\n",
    "            sent, tags = sent.to(device), tags.to(device)\n",
    "            sent = sent.unsqueeze(0)\n",
    "            tags = tags.unsqueeze(0)\n",
    "            losses.append(model.loss(sent, tags).cpu().detach().item())\n",
    "            score, pred_tag_seq = model(sent)\n",
    "            scores.append(score.cpu().detach().numpy())\n",
    "            true_tags.append([label_vocab.itos[i] for i in tags.tolist()[0]])\n",
    "            if model_name == 'crf':\n",
    "              pred_tags.append([label_vocab.itos[i] for i in pred_tag_seq])\n",
    "            else:\n",
    "              pred_tags.append([label_vocab.itos[i] for i in pred_tag_seq[0]])\n",
    "            sents.append([word_vocab.itos[i] for i in sent[0]])\n",
    "\n",
    "    print('Avg evaluation loss:', np.mean(losses))\n",
    "    labels = ['O', 'I-PER', 'I-ORG', 'I-LOC', 'I-MISC', 'B-MISC', 'B-ORG', 'B-LOC']\n",
    "    labels_map = ['O', 'PER', 'ORG', 'LOC', 'MISC', 'MISC', 'ORG', 'LOC']\n",
    "    final_labels = ['O', 'PER', 'ORG', 'LOC', 'MISC']\n",
    "    true_seqs = [labels_map[labels.index(tag)] for tags in true_tags for tag in tags]\n",
    "    pred_seqs = [labels_map[labels.index(tag)] for tags in pred_tags for tag in tags]\n",
    "    token_level_prec = precision_recall_fscore_support(true_seqs, pred_seqs, average=None, labels=final_labels)\n",
    "    token_level_overall = precision_recall_fscore_support(true_seqs, pred_seqs, average='macro')\n",
    "    for elem in token_level_prec:\n",
    "        print(elem)\n",
    "    print(\"Final F1\", token_level_overall)\n",
    "    print(conlleval_own.evaluate([tag for tags in true_tags for tag in tags], [tag for tags in pred_tags for tag in tags], verbose=True))\n",
    "    print('\\n5 random evaluation samples:')\n",
    "    for i in np.random.randint(0, len(sents), size=5):\n",
    "        print('SENT:', ' '.join(sents[i]))\n",
    "        print('TRUE:', ' '.join(true_tags[i]))\n",
    "        print('PRED:', ' '.join(pred_tags[i]))\n",
    "    return sents, true_tags, pred_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'crf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if model_name == 'crf':\n",
    "    model = BiLSTMCRFTagger(len(word_vocab), len(label_vocab), 128, 256).to(device)\n",
    "    model.load_state_dict(torch.load('models/ner_model_crf_14.pt', map_location=torch.device('cpu')))\n",
    "else:\n",
    "    model = BiLSTMTagger(len(word_vocab), len(label_vocab), 128, 256).to(device)\n",
    "    model.load_state_dict(torch.load('models/ner_model_trad_29.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg evaluation loss: 3.193943685144186\n",
      "[0.96802786 0.8189911  0.71459695 0.88511749 0.87570621]\n",
      "[0.9807569  0.86520376 0.66938776 0.7995283  0.58712121]\n",
      "[0.9743508  0.84146341 0.69125395 0.8401487  0.70294785]\n",
      "[9354  638  490  424  264]\n",
      "Final F1 (0.8524879225785025, 0.780399585262266, 0.8100329430752545, None)\n",
      "processed 11170 tokens with 1231 phrases; found: 1150 phrases; correct: 870.\n",
      "accuracy:  75.66%; (non-O)\n",
      "accuracy:  94.43%; precision:  75.65%; recall:  70.67%; FB1:  73.08\n",
      "              LOC: precision:  87.58%; recall:  79.61%; FB1:  83.41  330\n",
      "             MISC: precision:  84.33%; recall:  58.85%; FB1:  69.33  134\n",
      "              ORG: precision:  62.38%; recall:  61.56%; FB1:  61.97  303\n",
      "              PER: precision:  72.85%; recall:  75.61%; FB1:  74.20  383\n",
      "(75.65217391304347, 70.67424857839156, 73.0785384292314)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: \" Now many Russian banks are strong and can make various <unk> of money <unk> , while <unk> traders are being ousted by more <unk> ones .\n",
      "TRUE: O O O I-MISC O O O O O O O O O O O O O O O O O O O O O O O\n",
      "PRED: O O O I-MISC O O O O O O O O O O O O O O O O O O O O O O O\n",
      "SENT: -DOCSTART-\n",
      "TRUE: O\n",
      "PRED: O\n",
      "SENT: NAC Breda 0000 Sparta Rotterdam 0000\n",
      "TRUE: I-ORG I-ORG O I-ORG I-ORG O\n",
      "PRED: I-ORG I-ORG O I-ORG I-ORG O\n",
      "SENT: The defeat put the <unk> out of the <unk> Cup .\n",
      "TRUE: O O O O I-MISC O O O I-MISC I-MISC O\n",
      "PRED: O O O O O O O O I-MISC I-MISC O\n",
      "SENT: <unk> :\n",
      "TRUE: O O\n",
      "PRED: O O\n"
     ]
    }
   ],
   "source": [
    "x, y, z = evaluate_test(model, valid_data, word_vocab, label_vocab, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length wise analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first bin\n",
      "----------------------------------------------------------------\n",
      "Total 193 samples\n",
      "Avg evaluation loss: 0.7624233936398758\n",
      "[0.91666667 0.63636364 0.88461538 0.94871795 0.7       ]\n",
      "[0.96934866 0.60869565 0.80701754 0.85057471 0.7       ]\n",
      "[0.94227188 0.62222222 0.8440367  0.8969697  0.7       ]\n",
      "[261  23  57  87  10]\n",
      "Final F1 (0.8172727272727272, 0.7871273135362143, 0.8011000994517985, None)\n",
      "processed 438 tokens with 134 phrases; found: 129 phrases; correct: 103.\n",
      "accuracy:  79.66%; (non-O)\n",
      "accuracy:  89.95%; precision:  79.84%; recall:  76.87%; FB1:  78.33\n",
      "              LOC: precision:  86.89%; recall:  77.94%; FB1:  82.17  61\n",
      "             MISC: precision:  42.86%; recall:  60.00%; FB1:  50.00  7\n",
      "              ORG: precision:  85.42%; recall:  85.42%; FB1:  85.42  48\n",
      "              PER: precision:  46.15%; recall:  46.15%; FB1:  46.15  13\n",
      "(79.84496124031007, 76.86567164179104, 78.32699619771863)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: <unk> 0000 <unk> 0000\n",
      "TRUE: I-ORG O I-ORG O\n",
      "PRED: I-ORG O I-ORG O\n",
      "SENT: -DOCSTART-\n",
      "TRUE: O\n",
      "PRED: O\n",
      "SENT: <unk> :\n",
      "TRUE: O O\n",
      "PRED: O O\n",
      "SENT: -DOCSTART-\n",
      "TRUE: O\n",
      "PRED: O\n",
      "SENT: LONDON 1996-08-28\n",
      "TRUE: I-LOC O\n",
      "PRED: I-LOC O\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "second bin\n",
      "----------------------------------------------------------------\n",
      "Total 235 samples\n",
      "Avg evaluation loss: 2.0561995161340594\n",
      "[0.95280236 0.81294964 0.83006536 0.84883721 0.85185185]\n",
      "[0.97289157 0.87596899 0.78881988 0.8021978  0.44230769]\n",
      "[0.96274218 0.84328358 0.8089172  0.82485876 0.58227848]\n",
      "[1328  129  161   91   52]\n",
      "Final F1 (0.8593012841602155, 0.7764371857590028, 0.8044160386947035, None)\n",
      "processed 1761 tokens with 297 phrases; found: 272 phrases; correct: 218.\n",
      "accuracy:  77.60%; (non-O)\n",
      "accuracy:  92.45%; precision:  80.15%; recall:  73.40%; FB1:  76.63\n",
      "              LOC: precision:  84.42%; recall:  80.25%; FB1:  82.28  77\n",
      "             MISC: precision:  84.21%; recall:  43.24%; FB1:  57.14  19\n",
      "              ORG: precision:  79.80%; recall:  74.53%; FB1:  77.07  99\n",
      "              PER: precision:  75.32%; recall:  79.45%; FB1:  77.33  77\n",
      "(80.14705882352942, 73.4006734006734, 76.62565905096662)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: <unk> <unk> ( <unk> grade ) , Midwest\n",
      "TRUE: O O O O O O O I-LOC\n",
      "PRED: I-PER I-PER O I-LOC O O O I-PER\n",
      "SENT: <unk> Bremen 0000 <unk> <unk> 0000\n",
      "TRUE: I-ORG I-ORG O I-ORG I-ORG O\n",
      "PRED: I-ORG I-ORG O I-ORG I-ORG O\n",
      "SENT: Martinez <unk> play against <unk> <unk> of Romania .\n",
      "TRUE: I-PER O O O I-PER I-PER O I-LOC O\n",
      "PRED: I-PER O O O I-PER I-PER O I-LOC O\n",
      "SENT: 2. <unk> <unk> ( Finland ) <unk> <unk> <unk>\n",
      "TRUE: O I-PER I-PER O I-LOC O I-MISC I-MISC O\n",
      "PRED: O I-PER I-PER O I-LOC O O O O\n",
      "SENT: It was the second arms <unk> this week .\n",
      "TRUE: O O O O O O O O O\n",
      "PRED: O O O O O O O O O\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "third bin\n",
      "----------------------------------------------------------------\n",
      "Total 161 samples\n",
      "Avg evaluation loss: 2.7482424433927357\n",
      "[0.98067393 0.82828283 0.54411765 0.8902439  0.68085106]\n",
      "[0.96819961 0.92655367 0.62711864 0.84883721 0.68085106]\n",
      "[0.97439685 0.87466667 0.58267717 0.86904762 0.68085106]\n",
      "[2044  177   59   86   47]\n",
      "Final F1 (0.784833875239833, 0.8103120396253722, 0.7963278727482677, None)\n",
      "processed 2413 tokens with 250 phrases; found: 259 phrases; correct: 184.\n",
      "accuracy:  82.93%; (non-O)\n",
      "accuracy:  94.70%; precision:  71.04%; recall:  73.60%; FB1:  72.30\n",
      "              LOC: precision:  88.57%; recall:  83.78%; FB1:  86.11  70\n",
      "             MISC: precision:  67.74%; recall:  56.76%; FB1:  61.76  31\n",
      "              ORG: precision:  44.68%; recall:  52.50%; FB1:  48.28  47\n",
      "              PER: precision:  72.07%; recall:  80.81%; FB1:  76.19  111\n",
      "(71.04247104247105, 73.6, 72.29862475442043)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: They said the index could also rise towards <unk> if the <unk> share prices <unk> buyers .\n",
      "TRUE: O O O O O O O O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O O O\n",
      "SENT: He would continue working on various <unk> and might meet \" one state <unk> or another \" .\n",
      "TRUE: O O O O O O O O O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O O O O\n",
      "SENT: Nigeria is under fire from many Western countries for human rights <unk> and lack of democracy .\n",
      "TRUE: I-LOC O O O O O I-MISC O O O O O O O O O O\n",
      "PRED: I-LOC O O O O O I-MISC O O O O O O O O O O\n",
      "SENT: Our <unk> is <unk> , <unk> and respect , \" she said .\n",
      "TRUE: O O O O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O\n",
      "SENT: Barbara <unk> ( Germany ) beat 0000 - <unk> <unk> (\n",
      "TRUE: I-PER I-PER O I-LOC O O O O I-PER I-PER O\n",
      "PRED: I-PER I-PER O I-LOC O O O O I-PER I-PER O\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "fourth bin\n",
      "----------------------------------------------------------------\n",
      "Total 210 samples\n",
      "Avg evaluation loss: 6.8859502156575525\n",
      "[0.96845754 0.79285714 0.62790698 0.8828125  0.92929293]\n",
      "[0.98797737 0.83146067 0.50704225 0.71518987 0.59354839]\n",
      "[0.97812008 0.81170018 0.56103896 0.79020979 0.72440945]\n",
      "[5656  267  213  158  155]\n",
      "Final F1 (0.8402654175778117, 0.7270437114716828, 0.7730956919800669, None)\n",
      "processed 6449 tokens with 525 phrases; found: 468 phrases; correct: 342.\n",
      "accuracy:  67.47%; (non-O)\n",
      "accuracy:  94.94%; precision:  73.08%; recall:  65.14%; FB1:  68.88\n",
      "              LOC: precision:  88.50%; recall:  74.07%; FB1:  80.65  113\n",
      "             MISC: precision:  88.89%; recall:  64.29%; FB1:  74.61  81\n",
      "              ORG: precision:  47.12%; recall:  43.75%; FB1:  45.37  104\n",
      "              PER: precision:  71.18%; recall:  72.89%; FB1:  72.02  170\n",
      "(73.07692307692307, 65.14285714285715, 68.8821752265861)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: <unk> <unk> of Finland , driving a <unk> , on Monday won the 1,000 Lakes Rally , sixth round of the world championship .\n",
      "TRUE: I-PER I-PER O I-LOC O O O I-ORG O O O O O I-MISC I-MISC I-MISC O O O O O O O O\n",
      "PRED: I-PER O O I-LOC O O O O O O O O O I-MISC I-MISC I-MISC O O O O O O O O\n",
      "SENT: King <unk> left Nepal on Friday for a <unk> visit to China , his eighth since <unk> the <unk> in 0000 , officials said .\n",
      "TRUE: O I-PER O I-LOC O O O O O O O I-LOC O O O O O O O O O O O O O\n",
      "PRED: O O O I-LOC O O O O O O O I-LOC O O O O O O O O O O O O O\n",
      "SENT: State media quoted China 's top <unk> with <unk> , <unk> <unk> , as <unk> a visiting group from Taiwan on Wednesday that it was time for the rivals to hold political talks .\n",
      "TRUE: O O O I-LOC O O O O I-LOC O I-PER I-PER O O O O O O O I-LOC O O O O O O O O O O O O O O\n",
      "PRED: I-ORG O O I-LOC O O O O I-ORG O I-PER I-PER O O O O O O O I-LOC O O O O O O O O O O O O O O\n",
      "SENT: All <unk> 's Association secretary N.J. <unk> said the strike would continue <unk> and the fishermen would block road and rail traffic if their <unk> were not met .\n",
      "TRUE: I-ORG I-ORG I-ORG I-ORG O I-PER I-PER O O O O O O O O O O O O O O O O O O O O O O\n",
      "PRED: O I-PER O I-ORG O I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O\n",
      "SENT: The <unk> Woods , who turned <unk> Tuesday after winning an <unk> third successive U.S. <unk> <unk> , <unk> on the front nine , <unk> the first and seventh <unk> and <unk> the <unk> , <unk> ninth <unk> .\n",
      "TRUE: O O I-PER O O O O O O O O O O O I-MISC I-MISC I-MISC O O O O O O O O O O O O O O O O O O O O O O\n",
      "PRED: O O I-PER O O O O O O O O O O O I-LOC O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Makes bins based on various length sizes. Divided data into 4 categories\n",
    "valid_data_binned = {}\n",
    "a1 = 1\n",
    "a2 = 5\n",
    "a3 = 11\n",
    "a4 = 21\n",
    "a5 = 100\n",
    "first_list = [[sent, tag] for sent, tag in valid_data if len(sent) >= a1 and len(sent) < a2]\n",
    "second_list = [[sent, tag] for sent, tag in valid_data if len(sent) >= a2 and len(sent) < a3]\n",
    "third_list = [[sent, tag] for sent, tag in valid_data if len(sent) >= a3 and len(sent) < a4]\n",
    "fourth_list = [[sent, tag] for sent, tag in valid_data if len(sent) >= a4 and len(sent) < a5]\n",
    "valid_data_binned[\"first\"] = first_list\n",
    "valid_data_binned[\"second\"] = second_list\n",
    "valid_data_binned[\"third\"] = third_list\n",
    "valid_data_binned[\"fourth\"] = fourth_list\n",
    "\n",
    "\n",
    "for key in valid_data_binned.keys():\n",
    "    val_data = valid_data_binned[key]\n",
    "    print(\"{} bin\".format(key))\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"Total {} samples\".format(len(val_data)))\n",
    "    x, y, z = evaluate_test(model, val_data, word_vocab, label_vocab, model_name)\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rare words analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Segregate the entire data into multiple bins based on of a rare word is present in that sentence\n",
    "rare_word_thres = 10\n",
    "word_freqs = dict(word_vocab.freqs)\n",
    "rare_words = [word for word in word_freqs.keys() if (word_freqs[word]>1 and word_freqs[word]<rare_word_thres)]\n",
    "rare_words_idx = [word_vocab.stoi[word] for word in rare_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare Words\n",
      "----------------------------------------------------------------\n",
      "Total 585 samples\n",
      "Avg evaluation loss: 3.8367885577373015\n",
      "[0.96991371 0.81530782 0.69722222 0.89285714 0.83516484]\n",
      "[0.98139001 0.87033748 0.63224181 0.7994186  0.608     ]\n",
      "[0.97561811 0.8419244  0.66314399 0.84355828 0.7037037 ]\n",
      "[8705  563  397  344  250]\n",
      "Final F1 (0.8420931470696849, 0.7782775803589033, 0.805589697245831, None)\n",
      "processed 10259 tokens with 1040 phrases; found: 976 phrases; correct: 727.\n",
      "accuracy:  75.16%; (non-O)\n",
      "accuracy:  94.66%; precision:  74.49%; recall:  69.90%; FB1:  72.12\n",
      "              LOC: precision:  88.39%; recall:  80.00%; FB1:  83.99  267\n",
      "             MISC: precision:  78.20%; recall:  57.46%; FB1:  66.24  133\n",
      "              ORG: precision:  58.80%; recall:  57.81%; FB1:  58.30  233\n",
      "              PER: precision:  72.89%; recall:  76.45%; FB1:  74.63  343\n",
      "(74.48770491803278, 69.90384615384615, 72.12301587301586)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: The <unk> American <unk> off the Stadium Court for <unk> of an upset stomach after his two and a half hour struggle against <unk> .\n",
      "TRUE: O O I-MISC O O O I-LOC I-LOC O O O O O O O O O O O O O O O I-PER O\n",
      "PRED: O O I-MISC O O O I-LOC I-LOC O O O O O O O O O O O O O O O I-MISC O\n",
      "SENT: CRICKET - ENGLAND <unk> <unk> FOR ONE-DAY <unk> .\n",
      "TRUE: O O I-LOC O O O O O O\n",
      "PRED: O O I-LOC O O O O O O\n",
      "SENT: The town 's <unk> <unk> ground is <unk> only by two <unk> <unk> .\n",
      "TRUE: O O O O O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O\n",
      "SENT: The <unk> will visit <unk> before <unk> in the Chinese capital , Beijing , early next week , officials said .\n",
      "TRUE: O O O O I-LOC O O O O I-MISC O O I-LOC O O O O O O O O\n",
      "PRED: O O O O O O O O O I-MISC O O I-LOC O O O O O O O O\n",
      "SENT: What he did was bad for <unk> , bad for the crowd and bad for the sponsors .\n",
      "TRUE: O O O O O O O O O O O O O O O O O O\n",
      "PRED: O O O O O O O O O O O O O O O O O O\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "valid_data_rare = []\n",
    "for sent, tag in valid_data:\n",
    "    word_list = sent.tolist()\n",
    "    for word in word_list:\n",
    "        if word in rare_words_idx:\n",
    "            valid_data_rare.append([sent, tag])\n",
    "            break\n",
    "\n",
    "print(\"Rare Words\")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"Total {} samples\".format(len(valid_data_rare)))\n",
    "x, y, z = evaluate_test(model, valid_data_rare, word_vocab, label_vocab, model_name)\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"----------------------------------------------------------------\")         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOV words Analysis Token level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(model, dataset, word_vocab, label_vocab, model_name):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    scores = []\n",
    "    true_tags = []\n",
    "    pred_tags = []\n",
    "    sents = []\n",
    "    for i, (sent, tags) in enumerate(dataset):\n",
    "        with torch.no_grad():\n",
    "            sent, tags = sent.to(device), tags.to(device)\n",
    "            sent = sent.unsqueeze(0)\n",
    "            tags = tags.unsqueeze(0)\n",
    "            losses.append(model.loss(sent, tags).cpu().detach().item())\n",
    "            score, pred_tag_seq = model(sent)\n",
    "            scores.append(score.cpu().detach().numpy())\n",
    "            true_tags.append([label_vocab.itos[i] for i in tags.tolist()[0]])\n",
    "            if model_name == 'crf':\n",
    "              pred_tags.append([label_vocab.itos[i] for i in pred_tag_seq])\n",
    "            else:\n",
    "              pred_tags.append([label_vocab.itos[i] for i in pred_tag_seq[0]])\n",
    "            sents.append([word_vocab.itos[i] for i in sent[0]])\n",
    "\n",
    "    print('Avg evaluation loss:', np.mean(losses))\n",
    "    labels = ['O', 'I-PER', 'I-ORG', 'I-LOC', 'I-MISC', 'B-MISC', 'B-ORG', 'B-LOC']\n",
    "    labels_map = ['O', 'PER', 'ORG', 'LOC', 'MISC', 'MISC', 'ORG', 'LOC']\n",
    "    final_labels = ['O', 'PER', 'ORG', 'LOC', 'MISC']\n",
    "    true_seqs = []\n",
    "    pred_seqs = []\n",
    "    for word, true_tag, pred_tag in zip(sents, true_tags, pred_tags):\n",
    "        #print(word)\n",
    "        for word_1, true_tag_1, pred_tag_1 in zip(word, true_tag, pred_tag):\n",
    "            if word_1 == \"<unk>\":\n",
    "                true_seqs.append(labels_map[labels.index(true_tag_1)])\n",
    "                pred_seqs.append(labels_map[labels.index(pred_tag_1)])\n",
    "\n",
    "    token_level_prec = precision_recall_fscore_support(true_seqs, pred_seqs, average=None, labels=final_labels)\n",
    "    token_level_overall = precision_recall_fscore_support(true_seqs, pred_seqs, average='macro')\n",
    "    for elem in token_level_prec:\n",
    "        print(elem)\n",
    "    print(\"Final F1\", token_level_overall)\n",
    "    print(conlleval_own.evaluate([tag for tags in true_tags for tag in tags], [tag for tags in pred_tags for tag in tags], verbose=True))\n",
    "    print('\\n5 random evaluation samples:')\n",
    "    for i in np.random.randint(0, len(sents), size=5):\n",
    "        print('SENT:', ' '.join(sents[i]))\n",
    "        print('TRUE:', ' '.join(true_tags[i]))\n",
    "        print('PRED:', ' '.join(pred_tags[i]))\n",
    "    return sents, true_tags, pred_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOV words performance\n",
      "Avg evaluation loss: 0.146268008757586\n",
      "[0.98245614 0.97487844 0.96870343 0.96753247 0.98378378]\n",
      "[0.98924731 0.97251415 0.95870206 0.94006309 0.94300518]\n",
      "[0.98584003 0.97369486 0.9636768  0.9536     0.96296296]\n",
      "[3906 1237  678  317  193]\n",
      "Final F1 (0.9754708526942457, 0.9607063593369333, 0.9679549303174797, None)\n",
      "processed 46565 tokens with 5279 phrases; found: 5267 phrases; correct: 5171.\n",
      "accuracy:  98.70%; (non-O)\n",
      "accuracy:  99.69%; precision:  98.18%; recall:  97.95%; FB1:  98.07\n",
      "              LOC: precision:  99.04%; recall:  98.54%; FB1:  98.79  1564\n",
      "             MISC: precision:  99.22%; recall:  98.08%; FB1:  98.65  771\n",
      "              ORG: precision:  97.57%; recall:  97.70%; FB1:  97.64  1439\n",
      "              PER: precision:  97.32%; recall:  97.52%; FB1:  97.42  1493\n",
      "(98.17733054869944, 97.95415798446675, 98.06561729565712)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: Saeed Anwar c Croft b Cork 0000\n",
      "TRUE: I-PER I-PER O I-PER O I-PER O\n",
      "PRED: I-PER I-PER O I-PER O I-PER O\n",
      "SENT: PRESS DIGEST - <unk> - AUG 0000 .\n",
      "TRUE: O O O I-LOC O O O O\n",
      "PRED: O O O I-LOC O O O O\n",
      "SENT: Philadelphia 0000 SAN DIEGO 0000\n",
      "TRUE: I-ORG O I-ORG I-ORG O\n",
      "PRED: I-ORG O I-ORG I-ORG O\n",
      "SENT: Rosado ( 5-3 ) allowed two runs -- one earned -- and seven hits over <unk> innings with three <unk> and six <unk> .\n",
      "TRUE: I-PER O O O O O O O O O O O O O O O O O O O O O O O\n",
      "PRED: I-PER O O O O O O O O O O O O O O O O O O O O O O O\n",
      "SENT: <unk> <unk> ( Sweden ) beat Carlos Costa ( Spain ) 7-5 4-6 7-6 ( 7-4 ) 6-3\n",
      "TRUE: I-PER I-PER O I-LOC O O I-PER I-PER O I-LOC O O O O O O O O\n",
      "PRED: I-PER I-PER O I-LOC O O I-PER I-PER O I-LOC O O O O O O O O\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"OOV words performance\")\n",
    "x, y, z = evaluate_test(model, train_data, word_vocab, label_vocab, model_name)\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"----------------------------------------------------------------\")         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOV word analysis span level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOV Words\n",
      "----------------------------------------------------------------\n",
      "Total 638 samples\n",
      "Avg evaluation loss: 3.962669092005697\n",
      "[0.96424946 0.81859756 0.68734491 0.86875    0.84713376]\n",
      "[0.97960587 0.85645933 0.62811791 0.76164384 0.54958678]\n",
      "[0.97186701 0.83710055 0.6563981  0.81167883 0.66666667]\n",
      "[8728  627  441  365  242]\n",
      "Final F1 (0.8372151392789222, 0.7550827445259002, 0.7887422312635501, None)\n",
      "processed 10403 tokens with 1127 phrases; found: 1038 phrases; correct: 768.\n",
      "accuracy:  73.13%; (non-O)\n",
      "accuracy:  93.96%; precision:  73.99%; recall:  68.15%; FB1:  70.95\n",
      "              LOC: precision:  86.48%; recall:  76.42%; FB1:  81.14  281\n",
      "             MISC: precision:  81.51%; recall:  54.49%; FB1:  65.32  119\n",
      "              ORG: precision:  59.85%; recall:  58.74%; FB1:  59.29  264\n",
      "              PER: precision:  72.19%; recall:  74.59%; FB1:  73.37  374\n",
      "(73.98843930635837, 68.1455190771961, 70.94688221709006)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: Graham Thorpe 0000 0000 0000 0000 0000 <unk>\n",
      "TRUE: I-PER I-PER O O O O O O\n",
      "PRED: I-ORG I-ORG O O O O O O\n",
      "SENT: <unk> said <unk> the meeting carried <unk> for Singapore , \" however , this is <unk> <unk> as the <unk> <unk> may not <unk> lead to any additional investment and trade <unk> to this region . \"\n",
      "TRUE: I-PER O O O O O O O I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "PRED: I-PER O O O O O O O I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "SENT: \" The plant is <unk> as <unk> , \" Jose <unk> <unk> , director of <unk> , told Spanish state television .\n",
      "TRUE: O O O O O O O O O I-PER I-PER I-PER O O O O O O I-MISC O O O\n",
      "PRED: O O O O O O O O O I-PER I-PER I-PER O O O I-LOC O O I-MISC O O O\n",
      "SENT: \" We <unk> to start international telephone business as soon as possible , \" a company official told Reuters .\n",
      "TRUE: O O O O O O O O O O O O O O O O O O I-ORG O\n",
      "PRED: O O O O O O O O O O O O O O O O O O I-ORG O\n",
      "SENT: At Leicester : <unk> drawn .\n",
      "TRUE: O I-LOC O O O O\n",
      "PRED: O I-LOC O O O O\n",
      "----------------------------------------------------------------\n",
      "Non-OOV Words\n",
      "Total 162 samples\n",
      "Avg evaluation loss: 0.23499705762038997\n",
      "[0.99839744 1.         0.93478261 0.95081967 0.88      ]\n",
      "[0.99520767 1.         0.87755102 0.98305085 1.        ]\n",
      "[0.9968     1.         0.90526316 0.96666667 0.93617021]\n",
      "[626  11  49  59  22]\n",
      "Final F1 (0.9527999433448471, 0.9711619071194839, 0.9609800074654722, None)\n",
      "processed 767 tokens with 101 phrases; found: 102 phrases; correct: 94.\n",
      "accuracy:  95.04%; (non-O)\n",
      "accuracy:  98.70%; precision:  92.16%; recall:  93.07%; FB1:  92.61\n",
      "              LOC: precision:  95.56%; recall:  95.56%; FB1:  95.56  45\n",
      "             MISC: precision:  80.00%; recall:  92.31%; FB1:  85.71  15\n",
      "              ORG: precision:  91.43%; recall:  88.89%; FB1:  90.14  35\n",
      "              PER: precision: 100.00%; recall: 100.00%; FB1: 100.00  7\n",
      "(92.15686274509804, 93.06930693069307, 92.61083743842364)\n",
      "\n",
      "5 random evaluation samples:\n",
      "SENT: -DOCSTART-\n",
      "TRUE: O\n",
      "PRED: O\n",
      "SENT: -DOCSTART-\n",
      "TRUE: O\n",
      "PRED: O\n",
      "SENT: Reuters has not verified these stories and does not vouch for their accuracy .\n",
      "TRUE: I-ORG O O O O O O O O O O O O O\n",
      "PRED: I-ORG O O O O O O O O O O O O O\n",
      "SENT: Reuters has not verified these stories and does not vouch for their accuracy .\n",
      "TRUE: I-ORG O O O O O O O O O O O O O\n",
      "PRED: I-ORG O O O O O O O O O O O O O\n",
      "SENT: England\n",
      "TRUE: I-LOC\n",
      "PRED: I-LOC\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "valid_data_oov = []\n",
    "valid_data_non_oov = []\n",
    "for sent, tag in valid_data:\n",
    "    word_list = sent.tolist()\n",
    "    if 0 in word_list:\n",
    "        valid_data_oov.append([sent, tag])\n",
    "    else:\n",
    "        valid_data_non_oov.append([sent, tag])\n",
    "        \n",
    "\n",
    "print(\"OOV Words\")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"Total {} samples\".format(len(valid_data_oov)))\n",
    "x, y, z = evaluate_test(model, valid_data_oov, word_vocab, label_vocab, model_name)\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"Non-OOV Words\")\n",
    "print(\"Total {} samples\".format(len(valid_data_non_oov)))\n",
    "x, y, z = evaluate_test(model, valid_data_non_oov, word_vocab, label_vocab, model_name)\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"----------------------------------------------------------------\")         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if model_name == 'crf':\n",
    "    model = BiLSTMCRFTagger(len(word_vocab), len(label_vocab), 128, 256).to(device)\n",
    "    model.load_state_dict(torch.load('models/ner_model_crf_14.pt', map_location=torch.device('cpu')))\n",
    "else:\n",
    "    model = BiLSTMTagger(len(word_vocab), len(label_vocab), 128, 256).to(device)\n",
    "    model.load_state_dict(torch.load('models/ner_model_trad_29.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define an evaluate function for doing qualitative studies\n",
    "def evaluate_test_sample(model, dataset, word_vocab, label_vocab, model_name):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    scores = []\n",
    "    true_tags = []\n",
    "    pred_tags = []\n",
    "    sents = []\n",
    "    for i, (sent, tags) in enumerate(dataset):\n",
    "        with torch.no_grad():\n",
    "            sent, tags = sent.to(device), tags.to(device)\n",
    "            sent = sent.unsqueeze(0)\n",
    "            tags = tags.unsqueeze(0)\n",
    "            losses.append(model.loss(sent, tags).cpu().detach().item())\n",
    "            score, pred_tag_seq = model(sent)\n",
    "            scores.append(score.cpu().detach().numpy())\n",
    "            true_tags.append([label_vocab.itos[i] for i in tags.tolist()[0]])\n",
    "            if model_name == 'crf':\n",
    "              pred_tags.append([label_vocab.itos[i] for i in pred_tag_seq])\n",
    "            else:\n",
    "              pred_tags.append([label_vocab.itos[i] for i in pred_tag_seq[0]])\n",
    "            sents.append([word_vocab.itos[i] for i in sent[0]])\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        print('Avg evaluation loss:', np.mean(losses))\n",
    "        print('SENT:', ' '.join(sents[i]))\n",
    "        print('TRUE:', ' '.join(true_tags[i]))\n",
    "        print('PRED:', ' '.join(pred_tags[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg evaluation loss: 2.3061952590942383\n",
      "SENT: <unk> Real Madrid <unk>\n",
      "TRUE: O I-ORG I-ORG O\n",
      "PRED: I-ORG I-ORG I-ORG O\n"
     ]
    }
   ],
   "source": [
    "## Code for running single samples and doing qualitative studies\n",
    "evaluate_test_sample(model, valid_data[160:161], word_vocab, label_vocab, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cse291_assignment2_starter_code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
